{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fc94ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import plotly.express as px\n",
    "import io\n",
    "\n",
    "\n",
    "# pipeline.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9467f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 0. CONFIG\n",
    "# ==============================\n",
    "\n",
    "# Where to save local CSVs\n",
    "DATA_DIR = Path(\"data\")\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Remote sources\n",
    "HEALTH_URL = \"https://storage.googleapis.com/covid19-open-data/v3/health.csv\"\n",
    "WORLD_BANK_BASE = \"https://api.worldbank.org/v2\"\n",
    "TARGET_YEAR = \"2022\"\n",
    "\n",
    "# World Bank indicators (you can enrich later with the others if you want)\n",
    "INDICATORS = {\n",
    "    \"NY.GDP.MKTP.CD\": \"GDP (current US$)\",\n",
    "    \"NY.GDP.PCAP.CD\": \"GDP per capita (current US$)\",\n",
    "    \"SL.UEM.TOTL.ZS\": \"Unemployment rate (% of labor force)\",\n",
    "    \"NY.GDP.MKTP.KD\": \"GDP (constant 2015 US$)\",\n",
    "}\n",
    "\n",
    "GDP_PER_CAPITA_INDICATOR = \"NY.GDP.PCAP.CD\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83cae71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 1. RETRIEVAL\n",
    "# ==============================\n",
    "\n",
    "def fetch_health_data():\n",
    "    \"\"\"Download base health.csv and return as DataFrame named `health`.\"\"\"\n",
    "    print(f\"Downloading health data from: {HEALTH_URL}\")\n",
    "    health = pd.read_csv(HEALTH_URL)\n",
    "\n",
    "    print(\"✓ Raw health data loaded from remote health.csv\")\n",
    "    print(f\"  Shape: {health.shape[0]:,} rows × {health.shape[1]} columns\")\n",
    "    print(f\"  Columns (first 10): {list(health.columns)[:10]} ...\\n\")\n",
    "\n",
    "    # Save locally\n",
    "    health.to_csv(DATA_DIR / \"health.csv\", index=False)\n",
    "    print(f\"✓ Saved health.csv to {DATA_DIR.resolve()}\\n\")\n",
    "\n",
    "    return health\n",
    "\n",
    "\n",
    "def fetch_worldbank_gdp_per_capita(countries):\n",
    "    \"\"\"\n",
    "    Fetch REAL GDP per capita data from World Bank API\n",
    "    for a list of ISO country codes.\n",
    "    Returns DataFrame named `economic_data`.\n",
    "    \"\"\"\n",
    "    print(\"Endpoint: https://api.worldbank.org/v2/\")\n",
    "    print(\"Attempting to fetch REAL data from World Bank API...\\n\")\n",
    "\n",
    "    economic_data_list = []\n",
    "\n",
    "    for country_code in countries:\n",
    "        try:\n",
    "            gdp_url = (\n",
    "                f\"{WORLD_BANK_BASE}/country/{country_code}/indicators/\"\n",
    "                f\"{GDP_PER_CAPITA_INDICATOR}?format=json&date={TARGET_YEAR}\"\n",
    "            )\n",
    "\n",
    "            print(f\"  {country_code}: Connecting to API... \", end=\"\")\n",
    "            gdp_response = requests.get(gdp_url, timeout=60)\n",
    "\n",
    "            if gdp_response.status_code == 200:\n",
    "                gdp_data = gdp_response.json()\n",
    "\n",
    "                # Extract REAL values from API response\n",
    "                if gdp_data and len(gdp_data) > 1 and gdp_data[1]:\n",
    "                    data_point = gdp_data[1][0]\n",
    "                    gdp_value = data_point.get(\"value\")\n",
    "\n",
    "                    if gdp_value is not None:\n",
    "                        economic_data_list.append({\n",
    "                            \"location_key\": country_code,\n",
    "                            \"gdp_per_capita_usd\": float(gdp_value),\n",
    "                            \"data_year\": data_point.get(\"date\"),\n",
    "                            \"source\": \"World Bank API (REAL DATA)\",\n",
    "                        })\n",
    "                        print(f\"✓ Got REAL data: ${float(gdp_value):,.0f}\")\n",
    "                    else:\n",
    "                        print(\"✗ No value in response\")\n",
    "                else:\n",
    "                    print(\"✗ Empty response\")\n",
    "            else:\n",
    "                print(f\"✗ Status {gdp_response.status_code}\")\n",
    "\n",
    "        except requests.exceptions.Timeout:\n",
    "            print(\"⚠ Timeout\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error ({str(e)[:40]})\")\n",
    "\n",
    "    # Create DataFrame from fetched data\n",
    "    if economic_data_list:\n",
    "        economic_data = pd.DataFrame(economic_data_list)\n",
    "        print(\n",
    "            f\"\\nSuccessfully retrieved {len(economic_data)} countries \"\n",
    "            f\"with REAL World Bank data!\"\n",
    "        )\n",
    "        print(\"\\n   Sample:\")\n",
    "        print(economic_data[[\"location_key\", \"gdp_per_capita_usd\", \"data_year\"]].head())\n",
    "    else:\n",
    "        print(\"\\n⚠ No REAL data retrieved from API\")\n",
    "        print(\"   Creating empty DataFrame...\")\n",
    "        # Fallback placeholder if API fails\n",
    "        economic_data = pd.DataFrame({\n",
    "            \"location_key\": countries[:5],\n",
    "            \"gdp_per_capita_usd\": [np.nan] * 5,\n",
    "            \"source\": \"World Bank API (Attempted - No Data Retrieved)\",\n",
    "        })\n",
    "\n",
    "    # Save locally\n",
    "    economic_data.to_csv(DATA_DIR / \"economic_data.csv\", index=False)\n",
    "    print(f\"\\n✓ Saved economic_data.csv to {DATA_DIR.resolve()}\\n\")\n",
    "\n",
    "    return economic_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a38bba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 2. MERGE → df_clean\n",
    "# ==============================\n",
    "\n",
    "def build_df_clean(health, economic_data):\n",
    "    \"\"\"\n",
    "    Merge health + economic_data on `location_key`\n",
    "    to create df_clean (same name you used before).\n",
    "    \"\"\"\n",
    "    df_clean = health.merge(economic_data, how=\"left\", on=\"location_key\")\n",
    "    print(\n",
    "        f\"✓ Combined dataset df_clean: \"\n",
    "        f\"{df_clean.shape[0]:,} rows × {df_clean.shape[1]} columns\\n\"\n",
    "    )\n",
    "\n",
    "    # Save locally\n",
    "    df_clean.to_csv(DATA_DIR / \"df_clean.csv\", index=False)\n",
    "    print(f\"✓ Saved df_clean.csv to {DATA_DIR.resolve()}\\n\")\n",
    "\n",
    "    return df_clean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54e8d4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 3. CLEANING & ENRICHMENT\n",
    "# ==============================\n",
    "\n",
    "def clean_and_enrich(df_clean):\n",
    "    \"\"\"\n",
    "    Put the *key* cleaning + feature-engineering steps from enrichment.ipynb here.\n",
    "\n",
    "    For now I’m giving you a light, safe version that you can expand\n",
    "    by copy-pasting your existing enrichment code into this function\n",
    "    (but using df_clean instead of re-reading from Drive).\n",
    "    \"\"\"\n",
    "    df = df_clean.copy()\n",
    "\n",
    "    # make sure numeric cols are numeric\n",
    "    numeric_cols = [\n",
    "        c for c in df.columns\n",
    "        if df[c].dtype == \"object\" and c not in [\"location_key\", \"country_name\"]\n",
    "    ]\n",
    "    for col in numeric_cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"ignore\")\n",
    "\n",
    "    # derive a simple feature\n",
    "    if {\"new_confirmed\", \"population\"} <= set(df.columns):\n",
    "        df[\"cases_per_100k\"] = (\n",
    "            df[\"new_confirmed\"] / df[\"population\"] * 1e5\n",
    "        )\n",
    "\n",
    "\n",
    "    df_enriched = df\n",
    "\n",
    "    # Save enriched version if you want\n",
    "    df_enriched.to_csv(DATA_DIR / \"df_enriched.csv\", index=False)\n",
    "    print(f\"✓ Saved df_enriched.csv to {DATA_DIR.resolve()}\\n\")\n",
    "\n",
    "    return df_enriched\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00096c1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_enriched' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf_enriched\u001b[49m.head()\n",
      "\u001b[31mNameError\u001b[39m: name 'df_enriched' is not defined"
     ]
    }
   ],
   "source": [
    "df_enriched.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26e7b786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 4. BASIC ANALYSIS / CHECKS\n",
    "# ==============================\n",
    "\n",
    "def run_basic_analysis(df_enriched):\n",
    "    \"\"\"\n",
    "    Minimal analysis stub – you can copy plots / groupbys from analysis.ipynb here.\n",
    "    \"\"\"\n",
    "    print(\"=== BASIC SUMMARY ===\")\n",
    "    print(df_enriched.describe(include=\"all\").T.head())\n",
    "\n",
    "    # Example: top 10 countries by GDP per capita (where you have data)\n",
    "    if \"gdp_per_capita_usd\" in df_enriched.columns:\n",
    "        top_gdp = (\n",
    "            df_enriched\n",
    "            .dropna(subset=[\"gdp_per_capita_usd\"])\n",
    "            .sort_values(\"gdp_per_capita_usd\", ascending=False)\n",
    "            .head(10)[[\"location_key\", \"gdp_per_capita_usd\"]]\n",
    "        )\n",
    "        print(\"\\nTop 10 countries by GDP per capita:\")\n",
    "        print(top_gdp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc566bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading health data from: https://storage.googleapis.com/covid19-open-data/v3/health.csv\n",
      "✓ Raw health data loaded from remote health.csv\n",
      "  Shape: 3,504 rows × 14 columns\n",
      "  Columns (first 10): ['location_key', 'life_expectancy', 'smoking_prevalence', 'diabetes_prevalence', 'infant_mortality_rate', 'adult_male_mortality_rate', 'adult_female_mortality_rate', 'pollution_mortality_rate', 'comorbidity_mortality_rate', 'hospital_beds_per_1000'] ...\n",
      "\n",
      "✓ Saved health.csv to /Users/raynerjlee/Downloads/MA705/Project Health/data\n",
      "\n",
      "✓ Extracted 209 country codes for API enrichment\n",
      "  Sample countries: AD, AE, AF, AG, AL, AM, AO, AR, AT, AU\n",
      "\n",
      "Endpoint: https://api.worldbank.org/v2/\n",
      "Attempting to fetch REAL data from World Bank API...\n",
      "\n",
      "  AD: Connecting to API... ✓ Got REAL data: $42,414\n",
      "  AE: Connecting to API... ✓ Got REAL data: $49,899\n",
      "  AF: Connecting to API... ✓ Got REAL data: $357\n",
      "  AG: Connecting to API... ⚠ Timeout\n",
      "  AL: Connecting to API... ✓ Got REAL data: $6,846\n",
      "  AM: Connecting to API... ✓ Got REAL data: $6,572\n",
      "  AO: Connecting to API... ⚠ Timeout\n",
      "  AR: Connecting to API... ✓ Got REAL data: $13,936\n",
      "  AT: Connecting to API... ✓ Got REAL data: $52,177\n",
      "  AU: Connecting to API... ✓ Got REAL data: $64,997\n",
      "  AW: Connecting to API... ✓ Got REAL data: $30,560\n",
      "  AZ: Connecting to API... ⚠ Timeout\n",
      "  BA: Connecting to API... ⚠ Timeout\n",
      "  BB: Connecting to API... ⚠ Timeout\n",
      "  BD: Connecting to API... ⚠ Timeout\n",
      "  BE: Connecting to API... ⚠ Timeout\n",
      "  BF: Connecting to API... ✓ Got REAL data: $836\n",
      "  BG: Connecting to API... ✓ Got REAL data: $14,000\n",
      "  BH: Connecting to API... ⚠ Timeout\n",
      "  BI: Connecting to API... ✓ Got REAL data: $251\n",
      "  BJ: Connecting to API... ✓ Got REAL data: $1,266\n",
      "  BM: Connecting to API... ⚠ Timeout\n",
      "  BN: Connecting to API... ✗ Status 400\n",
      "  BO: Connecting to API... ⚠ Timeout\n",
      "  BR: Connecting to API... ✓ Got REAL data: $9,281\n",
      "  BS: Connecting to API... ⚠ Timeout\n",
      "  BT: Connecting to API... ⚠ Timeout\n",
      "  BW: Connecting to API... ⚠ Timeout\n",
      "  BY: Connecting to API... ✓ Got REAL data: $7,995\n",
      "  BZ: Connecting to API... ✓ Got REAL data: $7,068\n",
      "  CA: Connecting to API... ⚠ Timeout\n",
      "  CD: Connecting to API... ✓ Got REAL data: $643\n",
      "  CF: Connecting to API... ⚠ Timeout\n",
      "  CG: Connecting to API... "
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# 5. MAIN PIPELINE\n",
    "# ==============================\n",
    "\n",
    "def main():\n",
    "    # 1) Health retrieval\n",
    "    health = fetch_health_data()\n",
    "\n",
    "    # Extract country codes for API enrichment (same logic as before)\n",
    "    countries = (\n",
    "        health.loc[~health[\"location_key\"].str.contains(\"_\", na=False), \"location_key\"]\n",
    "        .dropna()\n",
    "        .unique()\n",
    "    )\n",
    "    print(f\"✓ Extracted {len(countries)} country codes for API enrichment\")\n",
    "    print(f\"  Sample countries: {', '.join(countries[:10])}\\n\")\n",
    "\n",
    "    # 2) Economic retrieval from World Bank\n",
    "    economic_data = fetch_worldbank_gdp_per_capita(countries)\n",
    "\n",
    "    # 3) Merge into df_clean\n",
    "    df_clean = build_df_clean(health, economic_data)\n",
    "\n",
    "    # 4) Cleaning + enrichment\n",
    "    df_enriched = clean_and_enrich(df_clean)\n",
    "\n",
    "    # 5) Simple analysis\n",
    "    run_basic_analysis(df_enriched)\n",
    "\n",
    "    print(\"\\n=== PIPELINE COMPLETE ===\")\n",
    "    print(\"Local files created in:\", DATA_DIR.resolve())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3089ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 4. ANALYSIS & PLOTS\n",
    "# ==============================\n",
    "\n",
    "# Make sure required columns exist or handle missing:\n",
    "required_cols = [\n",
    "    \"life_expectancy\",\n",
    "    \"infant_mortality_rate\",\n",
    "    \"adult_male_mortality_rate\",\n",
    "    \"adult_female_mortality_rate\",\n",
    "    \"pollution_mortality_rate\",\n",
    "    \"health_expenditure_usd\",\n",
    "    \"physicians_per_1000\",\n",
    "    \"nurses_per_1000\",\n",
    "    \"smoking_prevalence\",\n",
    "    \"diabetes_prevalence\"\n",
    "]\n",
    "\n",
    "missing_cols = [c for c in required_cols if c not in df_enriched.columns]\n",
    "if missing_cols:\n",
    "    print(\"⚠ WARNING: The following columns are missing from df_enriched:\")\n",
    "    print(\"   \", missing_cols)\n",
    "    print(\"   The analysis below may error unless you create/rename these columns accordingly.\\n\")\n",
    "\n",
    "# --- Meaningful Summary Statistics ---\n",
    "\n",
    "print(\"Life Expectancy Statistics (in years):\")\n",
    "print(f\"  Mean:      {df_enriched['life_expectancy'].mean():.2f}\")\n",
    "print(f\"  Median:    {df_enriched['life_expectancy'].median():.2f}\")\n",
    "print(f\"  Std Dev:   {df_enriched['life_expectancy'].std():.2f}\")\n",
    "print(f\"  Min:       {df_enriched['life_expectancy'].min():.2f}\")\n",
    "print(f\"  25th %ile: {df_enriched['life_expectancy'].quantile(0.25):.2f}\")\n",
    "print(f\"  75th %ile: {df_enriched['life_expectancy'].quantile(0.75):.2f}\")\n",
    "print(f\"  Max:       {df_enriched['life_expectancy'].max():.2f}\\n\")\n",
    "\n",
    "print(\"Infant Mortality Rate (per 1000 births):\")\n",
    "print(f\"  Mean:   {df_enriched['infant_mortality_rate'].mean():.2f}\")\n",
    "print(f\"  Median: {df_enriched['infant_mortality_rate'].median():.2f}\")\n",
    "print(f\"  Min:    {df_enriched['infant_mortality_rate'].min():.2f}\")\n",
    "print(f\"  Max:    {df_enriched['infant_mortality_rate'].max():.2f}\\n\")\n",
    "\n",
    "print(\"Health Expenditure (USD per capita):\")\n",
    "print(f\"  Mean:      ${df_enriched['health_expenditure_usd'].mean():.0f}\")\n",
    "print(f\"  Median:    ${df_enriched['health_expenditure_usd'].median():.0f}\")\n",
    "print(f\"  Min:       ${df_enriched['health_expenditure_usd'].min():.0f}\")\n",
    "print(f\"  Max:       ${df_enriched['health_expenditure_usd'].max():.0f}\")\n",
    "print(f\"  90th:      ${df_enriched['health_expenditure_usd'].quantile(0.9):.0f}\\n\")\n",
    "\n",
    "# --- Statistical & ML Analysis ---\n",
    "\n",
    "feature_cols = [\n",
    "    \"smoking_prevalence\", \"diabetes_prevalence\", \"infant_mortality_rate\",\n",
    "    \"adult_male_mortality_rate\", \"adult_female_mortality_rate\",\n",
    "    \"pollution_mortality_rate\", \"health_expenditure_usd\",\n",
    "    \"physicians_per_1000\", \"nurses_per_1000\"\n",
    "]\n",
    "\n",
    "X = df_enriched[feature_cols].fillna(df_enriched[feature_cols].median())\n",
    "y = df_enriched[\"life_expectancy\"]\n",
    "valid_idx = y.notna()\n",
    "X, y = X[valid_idx], y[valid_idx]\n",
    "\n",
    "# Split and scale\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Data prepared: {len(X)} samples, {X.shape[1]} features\")\n",
    "print(f\"Train: {len(X_train)}, Test: {len(X_test)}\\n\")\n",
    "\n",
    "# Train Linear Regression\n",
    "print(\"Training Linear Regression...\")\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "lr_test_r2 = r2_score(y_test, lr_model.predict(X_test_scaled))\n",
    "print(f\"  Test R²: {lr_test_r2:.4f}\\n\")\n",
    "\n",
    "# Train Random Forest\n",
    "print(\"Training Random Forest Regression...\")\n",
    "rf_model = RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "rf_test_r2 = r2_score(y_test, rf_model.predict(X_test_scaled))\n",
    "print(f\"  Test R²: {rf_test_r2:.4f}\\n\")\n",
    "\n",
    "print(f\"Best Model: Random Forest (R² = {rf_test_r2:.4f})\")\n",
    "\n",
    "# --- Life Expectancy Distribution ---\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Top 15\n",
    "top_15 = (df_enriched\n",
    "          .nlargest(15, \"life_expectancy\")[[\"location_key\", \"life_expectancy\"]]\n",
    "          .sort_values(\"life_expectancy\"))\n",
    "ax1.barh(top_15[\"location_key\"], top_15[\"life_expectancy\"], color=\"#2ecc71\")\n",
    "ax1.set_xlabel(\"Life Expectancy (years)\", fontsize=12, fontweight=\"bold\")\n",
    "ax1.set_title(\"Top 15 - Highest Life Expectancy\", fontsize=13, fontweight=\"bold\")\n",
    "ax1.set_xlim(75, 90)\n",
    "for i, v in enumerate(top_15[\"life_expectancy\"]):\n",
    "    ax1.text(v + 0.2, i, f\"{v:.1f}\", va=\"center\", fontweight=\"bold\")\n",
    "\n",
    "# Bottom 15\n",
    "bottom_15 = (df_enriched\n",
    "             .nsmallest(15, \"life_expectancy\")[[\"location_key\", \"life_expectancy\"]]\n",
    "             .sort_values(\"life_expectancy\"))\n",
    "ax2.barh(bottom_15[\"location_key\"], bottom_15[\"life_expectancy\"], color=\"#e74c3c\")\n",
    "ax2.set_xlabel(\"Life Expectancy (years)\", fontsize=12, fontweight=\"bold\")\n",
    "ax2.set_title(\"Bottom 15 - Lowest Life Expectancy\", fontsize=13, fontweight=\"bold\")\n",
    "ax2.set_xlim(50, 65)\n",
    "for i, v in enumerate(bottom_15[\"life_expectancy\"]):\n",
    "    ax2.text(v + 0.2, i, f\"{v:.1f}\", va=\"center\", fontweight=\"bold\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\n",
    "    f\"They have a \"\n",
    "    f\"{top_15['life_expectancy'].iloc[-1] - bottom_15['life_expectancy'].iloc[0]:.1f} \"\n",
    "    f\"year global gap\"\n",
    ")\n",
    "\n",
    "# --- Health Spending vs Life Expectancy ---\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "scatter = ax.scatter(\n",
    "    df_enriched[\"health_expenditure_usd\"],\n",
    "    df_enriched[\"life_expectancy\"],\n",
    "    s=100,\n",
    "    alpha=0.6,\n",
    "    c=df_enriched[\"infant_mortality_rate\"],\n",
    "    cmap=\"viridis\",\n",
    "    edgecolors=\"black\",\n",
    "    linewidth=0.5,\n",
    ")\n",
    "\n",
    "# Trend line\n",
    "z = np.polyfit(\n",
    "    df_enriched[\"health_expenditure_usd\"].fillna(0),\n",
    "    df_enriched[\"life_expectancy\"],\n",
    "    1,\n",
    ")\n",
    "p = np.poly1d(z)\n",
    "x_trend = np.linspace(0, df_enriched[\"health_expenditure_usd\"].max(), 100)\n",
    "ax.plot(x_trend, p(x_trend), \"r--\", alpha=0.8, linewidth=2.5, label=\"Trend\")\n",
    "\n",
    "ax.set_xlabel(\"Health Expenditure (USD per capita)\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_ylabel(\"Life Expectancy (years)\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_title(\"Relationship: Health Spending vs Life Expectancy\", fontsize=13, fontweight=\"bold\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(fontsize=11)\n",
    "cbar = plt.colorbar(scatter, ax=ax)\n",
    "cbar.set_label(\"Infant Mortality Rate\", fontsize=11, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "corr = df_enriched[\"health_expenditure_usd\"].corr(df_enriched[\"life_expectancy\"])\n",
    "print(f\"Positive correlation = {corr:.4f}\")\n",
    "\n",
    "# --- Correlation Heatmap ---\n",
    "\n",
    "corr_vars = [\n",
    "    \"life_expectancy\", \"health_expenditure_usd\", \"infant_mortality_rate\",\n",
    "    \"physicians_per_1000\", \"smoking_prevalence\", \"diabetes_prevalence\"\n",
    "]\n",
    "\n",
    "corr_matrix = df_enriched[corr_vars].corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", center=0,\n",
    "    square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8},\n",
    "    ax=ax, vmin=-1, vmax=1\n",
    ")\n",
    "ax.set_title(\"Correlation Matrix: Key Health Indicators\", fontsize=13, fontweight=\"bold\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Country Health Status Distribution ---\n",
    "\n",
    "df_enriched[\"health_status\"] = pd.cut(\n",
    "    df_enriched[\"life_expectancy\"],\n",
    "    bins=[0, 65, 75, 80, 100],\n",
    "    labels=[\"Low (≤65)\", \"Medium (65-75)\", \"High (75-80)\", \"Very High (>80)\"],\n",
    ")\n",
    "\n",
    "health_counts = df_enriched[\"health_status\"].value_counts()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "colors = [\"#e74c3c\", \"#f39c12\", \"#3498db\", \"#2ecc71\"]\n",
    "ax1.pie(\n",
    "    health_counts, labels=health_counts.index, autopct=\"%1.1f%%\",\n",
    "    colors=colors, startangle=90, textprops={\"fontsize\": 11, \"fontweight\": \"bold\"}\n",
    ")\n",
    "ax1.set_title(\"Distribution by Health Status\", fontsize=13, fontweight=\"bold\")\n",
    "\n",
    "ax2.bar(range(len(health_counts)), health_counts.values,\n",
    "        color=colors, edgecolor=\"black\", linewidth=1.5)\n",
    "ax2.set_xticks(range(len(health_counts)))\n",
    "ax2.set_xticklabels(health_counts.index, fontsize=11, fontweight=\"bold\")\n",
    "ax2.set_ylabel(\"Number of Countries\", fontsize=12, fontweight=\"bold\")\n",
    "ax2.set_title(\"Country Count\", fontsize=13, fontweight=\"bold\")\n",
    "ax2.grid(axis=\"y\", alpha=0.3)\n",
    "for i, v in enumerate(health_counts.values):\n",
    "    ax2.text(i, v + 1, str(v), ha=\"center\", fontweight=\"bold\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Mortality Indicators Comparison ---\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "mortality_data = [\n",
    "    df_enriched[\"infant_mortality_rate\"],\n",
    "    df_enriched[\"adult_male_mortality_rate\"],\n",
    "    df_enriched[\"adult_female_mortality_rate\"],\n",
    "    df_enriched[\"pollution_mortality_rate\"],\n",
    "]\n",
    "labels = [\"Infant\", \"Adult Male\", \"Adult Female\", \"Pollution\"]\n",
    "\n",
    "bp = ax.boxplot(\n",
    "    mortality_data,\n",
    "    labels=labels,\n",
    "    patch_artist=True,\n",
    "    medianprops=dict(color=\"red\", linewidth=2),\n",
    "    boxprops=dict(facecolor=\"lightblue\", alpha=0.7),\n",
    "    whiskerprops=dict(linewidth=1.5),\n",
    "    capprops=dict(linewidth=1.5),\n",
    ")\n",
    "\n",
    "ax.set_ylabel(\"Mortality Rate (per 1000)\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_title(\"Global Distribution of Mortality Indicators\", fontsize=13, fontweight=\"bold\")\n",
    "ax.grid(axis=\"y\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- ML Model Performance ---\n",
    "\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Linear Regression\n",
    "axes[0, 0].scatter(y_test, y_pred_lr, alpha=0.6, s=80, color=\"#3498db\")\n",
    "axes[0, 0].plot(\n",
    "    [y_test.min(), y_test.max()],\n",
    "    [y_test.min(), y_test.max()],\n",
    "    \"r--\", lw=2,\n",
    ")\n",
    "axes[0, 0].set_xlabel(\"Actual\", fontsize=11, fontweight=\"bold\")\n",
    "axes[0, 0].set_ylabel(\"Predicted\", fontsize=11, fontweight=\"bold\")\n",
    "axes[0, 0].set_title(f\"Linear Regression (R² = {lr_test_r2:.4f})\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Random Forest\n",
    "axes[0, 1].scatter(y_test, y_pred_rf, alpha=0.6, s=80, color=\"#2ecc71\")\n",
    "axes[0, 1].plot(\n",
    "    [y_test.min(), y_test.max()],\n",
    "    [y_test.min(), y_test.max()],\n",
    "    \"r--\", lw=2,\n",
    ")\n",
    "axes[0, 1].set_xlabel(\"Actual\", fontsize=11, fontweight=\"bold\")\n",
    "axes[0, 1].set_ylabel(\"Predicted\", fontsize=11, fontweight=\"bold\")\n",
    "axes[0, 1].set_title(f\"Random Forest (R² = {rf_test_r2:.4f})\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Residuals\n",
    "residuals_lr = y_test - y_pred_lr\n",
    "residuals_rf = y_test - y_pred_rf\n",
    "axes[1, 0].hist(\n",
    "    residuals_lr, bins=15, alpha=0.6, label=\"Linear\",\n",
    "    color=\"#3498db\", edgecolor=\"black\"\n",
    ")\n",
    "axes[1, 0].hist(\n",
    "    residuals_rf, bins=15, alpha=0.6, label=\"Random Forest\",\n",
    "    color=\"#2ecc71\", edgecolor=\"black\"\n",
    ")\n",
    "axes[1, 0].set_xlabel(\"Prediction Error\", fontsize=11, fontweight=\"bold\")\n",
    "axes[1, 0].set_ylabel(\"Frequency\", fontsize=11, fontweight=\"bold\")\n",
    "axes[1, 0].set_title(\"Error Distribution\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# Metrics\n",
    "lr_rmse = np.sqrt(np.mean(residuals_lr**2))\n",
    "rf_rmse = np.sqrt(np.mean(residuals_rf**2))\n",
    "metrics = [\"R² Score\", \"RMSE\"]\n",
    "x_pos = np.arange(len(metrics))\n",
    "axes[1, 1].bar(\n",
    "    x_pos - 0.175, [lr_test_r2, lr_rmse], 0.35,\n",
    "    label=\"Linear\", color=\"#3498db\"\n",
    ")\n",
    "axes[1, 1].bar(\n",
    "    x_pos + 0.175, [rf_test_r2, rf_rmse], 0.35,\n",
    "    label=\"Random Forest\", color=\"#2ecc71\"\n",
    ")\n",
    "axes[1, 1].set_xticks(x_pos)\n",
    "axes[1, 1].set_xticklabels(metrics, fontsize=11, fontweight=\"bold\")\n",
    "axes[1, 1].set_ylabel(\"Value\", fontsize=11, fontweight=\"bold\")\n",
    "axes[1, 1].set_title(\"Performance Metrics\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Random Forest performs better (R² = {rf_test_r2:.4f})\")\n",
    "print(f\"Linear Regression performs  (R² = {lr_test_r2:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
