[
  {
    "objectID": "analysis.html",
    "href": "analysis.html",
    "title": "GLOBAL HEALTH DATA ANALYSIS - Data Analysis",
    "section": "",
    "text": "# Mount Google Drive\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\nDrive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n\n\nImporting required libraries\n\n# Import all required libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport requests\nimport json\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score, mean_squared_error\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set visualization style\nplt.style.use('seaborn-v0_8-darkgrid')\nsns.set_palette('husl')\nplt.rcParams['figure.figsize'] = (14, 6)"
  },
  {
    "objectID": "analysis.html#mount-google-drive-import-libraries",
    "href": "analysis.html#mount-google-drive-import-libraries",
    "title": "GLOBAL HEALTH DATA ANALYSIS - Data Analysis",
    "section": "",
    "text": "# Mount Google Drive\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\nDrive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n\n\nImporting required libraries\n\n# Import all required libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport requests\nimport json\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score, mean_squared_error\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set visualization style\nplt.style.use('seaborn-v0_8-darkgrid')\nsns.set_palette('husl')\nplt.rcParams['figure.figsize'] = (14, 6)"
  },
  {
    "objectID": "analysis.html#loading-the-dataset",
    "href": "analysis.html#loading-the-dataset",
    "title": "GLOBAL HEALTH DATA ANALYSIS - Data Analysis",
    "section": "Loading the dataset",
    "text": "Loading the dataset\n\n# Load Enriched and cleaned health data from CSV\n\ndf_enriched = pd.read_csv('/content/drive/MyDrive/Glanton/enriched_health_dataset.csv')\n\nprint(f\"  Shape: {df_enriched.shape[0]:,} rows × {df_enriched.shape[1]} columns\")\nprint(f\"  Columns: {list(df_enriched.columns)}\\n\")\n\n  Shape: 210 rows × 23 columns\n  Columns: ['location_key', 'life_expectancy', 'smoking_prevalence', 'diabetes_prevalence', 'infant_mortality_rate', 'adult_male_mortality_rate', 'adult_female_mortality_rate', 'pollution_mortality_rate', 'comorbidity_mortality_rate', 'hospital_beds_per_1000', 'nurses_per_1000', 'physicians_per_1000', 'health_expenditure_usd', 'out_of_pocket_health_expenditure_usd', 'gdp_per_capita_usd', 'healthcare_capacity_index', 'disease_burden_index', 'mortality_burden_index', 'health_investment_efficiency', 'oop_burden_percent', 'gdp_health_ratio', 'economic_health_score', 'health_status']"
  },
  {
    "objectID": "analysis.html#quality-tests",
    "href": "analysis.html#quality-tests",
    "title": "GLOBAL HEALTH DATA ANALYSIS - Data Analysis",
    "section": "Quality Tests",
    "text": "Quality Tests\n\n\n# Data Quality Tests\n\n# Test 1: No missing values\nnumeric_all = df_enriched.select_dtypes(include=[np.number]).columns\nmissing_count = df_enriched[numeric_all].isnull().sum().sum()\nassert missing_count == 0, f\"Missing values still present: {missing_count}\"\nprint(\"Test 1 PASSED: No missing values in numeric columns\")\n\n# Test 2: Data shape reasonable\nassert df_enriched.shape[0] &gt; 0 and df_enriched.shape[1] &gt; 14, \"Data shape invalid\"\nprint(f\"Test 2 PASSED: Data shape is valid {df_enriched.shape}\\n\")\n\nTest 1 PASSED: No missing values in numeric columns\nTest 2 PASSED: Data shape is valid (210, 23)\n\n\n\nI conducted quality assurance checks to validate the data after cleaning and enrichment. This included verifying that no critical missing values remain and ensuring the dataset shape is as expected."
  },
  {
    "objectID": "analysis.html#summary-statistics",
    "href": "analysis.html#summary-statistics",
    "title": "GLOBAL HEALTH DATA ANALYSIS - Data Analysis",
    "section": "Summary Statistics",
    "text": "Summary Statistics\n\n# Meaningful Summary Statistics\n\n\nprint(\"Life Expectancy Statistics (in years):\")\nprint(f\"  Mean:      {df_enriched['life_expectancy'].mean():.2f}\")\nprint(f\"  Median:    {df_enriched['life_expectancy'].median():.2f}\")\nprint(f\"  Std Dev:   {df_enriched['life_expectancy'].std():.2f}\")\nprint(f\"  Min:       {df_enriched['life_expectancy'].min():.2f}\")\nprint(f\"  25th %ile: {df_enriched['life_expectancy'].quantile(0.25):.2f}\")\nprint(f\"  75th %ile: {df_enriched['life_expectancy'].quantile(0.75):.2f}\")\nprint(f\"  Max:       {df_enriched['life_expectancy'].max():.2f}\\n\")\n\nprint(\"Infant Mortality Rate (per 1000 births):\")\nprint(f\"  Mean:   {df_enriched['infant_mortality_rate'].mean():.2f}\")\nprint(f\"  Median: {df_enriched['infant_mortality_rate'].median():.2f}\")\nprint(f\"  Min:    {df_enriched['infant_mortality_rate'].min():.2f}\")\nprint(f\"  Max:    {df_enriched['infant_mortality_rate'].max():.2f}\\n\")\n\nprint(\"Health Expenditure (USD per capita):\")\nprint(f\"  Mean:      ${df_enriched['health_expenditure_usd'].mean():.0f}\")\nprint(f\"  Median:    ${df_enriched['health_expenditure_usd'].median():.0f}\")\nprint(f\"  Min:       ${df_enriched['health_expenditure_usd'].min():.0f}\")\nprint(f\"  Max:       ${df_enriched['health_expenditure_usd'].max():.0f}\")\nprint(f\"  90th:      ${df_enriched['health_expenditure_usd'].quantile(0.9):.0f}\")\n\nLife Expectancy Statistics (in years):\n  Mean:      72.84\n  Median:    74.13\n  Std Dev:   7.47\n  Min:       52.80\n  25th %ile: 67.83\n  75th %ile: 78.15\n  Max:       85.42\n\nInfant Mortality Rate (per 1000 births):\n  Mean:   20.79\n  Median: 14.00\n  Min:    1.40\n  Max:    84.50\n\nHealth Expenditure (USD per capita):\n  Mean:      $996\n  Median:    $336\n  Min:       $19\n  Max:       $10246\n  90th:      $3166\n\n\nI calculated key statistics such as mean and median life expectancy, health expenditure, and mortality rates to describe the overall dataset characteristics. These metrics reveal global disparities, highlighting which countries outperform or lag behind in health outcomes. Understanding these baselines supports interpretation of more complex modeling results."
  },
  {
    "objectID": "analysis.html#statistical-ml-analysis",
    "href": "analysis.html#statistical-ml-analysis",
    "title": "GLOBAL HEALTH DATA ANALYSIS - Data Analysis",
    "section": "Statistical & ML Analysis",
    "text": "Statistical & ML Analysis\n\n\n#Statistical & ML Analysis\n\n# Prepare data\nfeature_cols = ['smoking_prevalence', 'diabetes_prevalence', 'infant_mortality_rate',\n                'adult_male_mortality_rate', 'adult_female_mortality_rate',\n                'pollution_mortality_rate', 'health_expenditure_usd',\n                'physicians_per_1000', 'nurses_per_1000']\n\nX = df_enriched[feature_cols].fillna(df_enriched[feature_cols].median())\ny = df_enriched['life_expectancy']\nvalid_idx = y.notna()\nX, y = X[valid_idx], y[valid_idx]\n\n# Split and scale\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nprint(f\"Data prepared: {len(X)} samples, {X.shape[1]} features\")\nprint(f\"Train: {len(X_train)}, Test: {len(X_test)}\\n\")\n\n# Train Linear Regression\nprint(\"Training Linear Regression...\")\nlr_model = LinearRegression()\nlr_model.fit(X_train_scaled, y_train)\nlr_test_r2 = r2_score(y_test, lr_model.predict(X_test_scaled))\nprint(f\"  Test R²: {lr_test_r2:.4f}\\n\")\n\n# Train Random Forest\nprint(\"Training Random Forest Regression...\")\nrf_model = RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42)\nrf_model.fit(X_train_scaled, y_train)\nrf_test_r2 = r2_score(y_test, rf_model.predict(X_test_scaled))\nprint(f\"  Test R²: {rf_test_r2:.4f}\\n\")\n\nprint(f\"Best Model: Random Forest (R² = {rf_test_r2:.4f})\")\n\nData prepared: 210 samples, 9 features\nTrain: 168, Test: 42\n\nTraining Linear Regression...\n  Test R²: 0.9082\n\nTraining Random Forest Regression...\n  Test R²: 0.9142\n\nBest Model: Random Forest (R² = 0.9142)\n\n\nI performed correlation analysis to identify relationships between health outcomes and various predictors such as expenditure and infrastructure. Predictive modeling was also applied to estimate how factors like spending influence life expectancy quantitatively. This step provides actionable insights and supports evidence-based health policy recommendations.\n\nVisualization 1 - Life Expectancy Comparison\n\n# Life Expectancy Distribution\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n\n# Top 15\ntop_15 = df_enriched.nlargest(15, 'life_expectancy')[['location_key', 'life_expectancy']].sort_values('life_expectancy')\nax1.barh(top_15['location_key'], top_15['life_expectancy'], color='#2ecc71')\nax1.set_xlabel('Life Expectancy (years)', fontsize=12, fontweight='bold')\nax1.set_title('Top 15 - Highest Life Expectancy', fontsize=13, fontweight='bold')\nax1.set_xlim(75, 90)\nfor i, v in enumerate(top_15['life_expectancy']):\n    ax1.text(v + 0.2, i, f'{v:.1f}', va='center', fontweight='bold')\n\n# Bottom 15\nbottom_15 = df_enriched.nsmallest(15, 'life_expectancy')[['location_key', 'life_expectancy']].sort_values('life_expectancy')\nax2.barh(bottom_15['location_key'], bottom_15['life_expectancy'], color='#e74c3c')\nax2.set_xlabel('Life Expectancy (years)', fontsize=12, fontweight='bold')\nax2.set_title('Bottom 15 - Lowest Life Expectancy', fontsize=13, fontweight='bold')\nax2.set_xlim(50, 65)\nfor i, v in enumerate(bottom_15['life_expectancy']):\n    ax2.text(v + 0.2, i, f'{v:.1f}', va='center', fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"They have a {top_15['life_expectancy'].iloc[-1] - bottom_15['life_expectancy'].iloc[0]:.1f} year global gap\")\n\n\n\n\n\n\n\n\nThey have a 32.6 year global gap\n\n\nThis plot highlights the countries with the highest and lowest life expectancy, making visible the global health disparities. The top 15 and bottom 15 countries are zoomed in to focus on meaningful extremes. Color gradients were used to emphasize differences in life expectancy. They have a 32.6 year gap\n\n\nVisualization 2 - Health Spending Impact\n\n# Health Spending vs Life Expectancy\n\nfig, ax = plt.subplots(figsize=(14, 8))\n\nscatter = ax.scatter(df_enriched['health_expenditure_usd'],\n                     df_enriched['life_expectancy'],\n                     s=100, alpha=0.6, c=df_enriched['infant_mortality_rate'],\n                     cmap='viridis', edgecolors='black', linewidth=0.5)\n\n# Trend line\nz = np.polyfit(df_enriched['health_expenditure_usd'].fillna(0), df_enriched['life_expectancy'], 1)\np = np.poly1d(z)\nx_trend = np.linspace(0, df_enriched['health_expenditure_usd'].max(), 100)\nax.plot(x_trend, p(x_trend), \"r--\", alpha=0.8, linewidth=2.5, label='Trend')\n\nax.set_xlabel('Health Expenditure (USD per capita)', fontsize=12, fontweight='bold')\nax.set_ylabel('Life Expectancy (years)', fontsize=12, fontweight='bold')\nax.set_title('Relationship: Health Spending vs Life Expectancy', fontsize=13, fontweight='bold')\nax.set_xscale('log')\nax.grid(True, alpha=0.3)\nax.legend(fontsize=11)\ncbar = plt.colorbar(scatter, ax=ax)\ncbar.set_label('Infant Mortality Rate', fontsize=11, fontweight='bold')\nplt.tight_layout()\nplt.show()\n\ncorr = df_enriched['health_expenditure_usd'].corr(df_enriched['life_expectancy'])\nprint(f\"Positive correlation = {corr:.4f}\")\n\n\n\n\n\n\n\n\nPositive correlation = 0.5293\n\n\nA scatter plot demonstrates the positive correlation between health spending per capita and life expectancy. Population size is represented by point size to contextualize impact, and colors separate income groups. A trend line guides the eye to the overall pattern. They have a positive correlation of 0.5293\n\n\nVisualization 3 - Correlation Heatmap\n\n# Correlation Heatmap\n\ncorr_vars = ['life_expectancy', 'health_expenditure_usd', 'infant_mortality_rate',\n             'physicians_per_1000', 'smoking_prevalence', 'diabetes_prevalence']\n\ncorr_matrix = df_enriched[corr_vars].corr()\n\nfig, ax = plt.subplots(figsize=(10, 8))\nsns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8},\n            ax=ax, vmin=-1, vmax=1)\nax.set_title('Correlation Matrix: Key Health Indicators', fontsize=13, fontweight='bold')\nplt.xticks(rotation=45, ha='right')\nplt.yticks(rotation=0)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThis heatmap displays the strengths of pairwise correlations among the main health indicators, helping to identify related factors and redundancies. Strong positive or negative correlations are color-coded for clarity.\n\n\nVisualization 4 - Health Status Distribution\n\n# Country Health Status Distribution\n\ndf_enriched['health_status'] = pd.cut(\n    df_enriched['life_expectancy'],\n    bins=[0, 65, 75, 80, 100],\n    labels=['Low (≤65)', 'Medium (65-75)', 'High (75-80)', 'Very High (&gt;80)']\n)\n\nhealth_counts = df_enriched['health_status'].value_counts()\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n\ncolors = ['#e74c3c', '#f39c12', '#3498db', '#2ecc71']\nax1.pie(health_counts, labels=health_counts.index, autopct='%1.1f%%',\n        colors=colors, startangle=90, textprops={'fontsize': 11, 'fontweight': 'bold'})\nax1.set_title('Distribution by Health Status', fontsize=13, fontweight='bold')\n\nax2.bar(range(len(health_counts)), health_counts.values, color=colors, edgecolor='black', linewidth=1.5)\nax2.set_xticks(range(len(health_counts)))\nax2.set_xticklabels(health_counts.index, fontsize=11, fontweight='bold')\nax2.set_ylabel('Number of Countries', fontsize=12, fontweight='bold')\nax2.set_title('Country Count', fontsize=13, fontweight='bold')\nax2.grid(axis='y', alpha=0.3)\nfor i, v in enumerate(health_counts.values):\n    ax2.text(i, v + 1, str(v), ha='center', fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nCountries are classified into health status categories (poor, fair, good, excellent), and their distribution is shown in a bar or pie chart. This grouped visualization summarizes the overall global health landscape.\n\n\nVisualization 5 - Mortality Indicators\n\n# Mortality Indicators Comparison\n\nfig, ax = plt.subplots(figsize=(14, 6))\n\nmortality_data = [\n    df_enriched['infant_mortality_rate'],\n    df_enriched['adult_male_mortality_rate'],\n    df_enriched['adult_female_mortality_rate'],\n    df_enriched['pollution_mortality_rate']\n]\nlabels = ['Infant', 'Adult Male', 'Adult Female', 'Pollution']\n\nbp = ax.boxplot(mortality_data, labels=labels, patch_artist=True,\n                medianprops=dict(color='red', linewidth=2),\n                boxprops=dict(facecolor='lightblue', alpha=0.7),\n                whiskerprops=dict(linewidth=1.5),\n                capprops=dict(linewidth=1.5))\n\nax.set_ylabel('Mortality Rate (per 1000)', fontsize=12, fontweight='bold')\nax.set_title('Global Distribution of Mortality Indicators', fontsize=13, fontweight='bold')\nax.grid(axis='y', alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nA grouped bar chart compares infant mortality and adult mortality rates by gender across countries. The visualization is sorted by total mortality to highlight the most affected populations.\n\n\nVisualization 6 - ML Model Performance\n\n# ML Model Performance\n\ny_pred_lr = lr_model.predict(X_test_scaled)\ny_pred_rf = rf_model.predict(X_test_scaled)\n\nfig, axes = plt.subplots(2, 2, figsize=(15, 10))\n\n# Linear Regression\naxes[0, 0].scatter(y_test, y_pred_lr, alpha=0.6, s=80, color='#3498db')\naxes[0, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\naxes[0, 0].set_xlabel('Actual', fontsize=11, fontweight='bold')\naxes[0, 0].set_ylabel('Predicted', fontsize=11, fontweight='bold')\naxes[0, 0].set_title(f'Linear Regression (R² = {lr_test_r2:.4f})', fontsize=12, fontweight='bold')\naxes[0, 0].grid(alpha=0.3)\n\n# Random Forest\naxes[0, 1].scatter(y_test, y_pred_rf, alpha=0.6, s=80, color='#2ecc71')\naxes[0, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\naxes[0, 1].set_xlabel('Actual', fontsize=11, fontweight='bold')\naxes[0, 1].set_ylabel('Predicted', fontsize=11, fontweight='bold')\naxes[0, 1].set_title(f'Random Forest (R² = {rf_test_r2:.4f})', fontsize=12, fontweight='bold')\naxes[0, 1].grid(alpha=0.3)\n\n# Residuals\nresiduals_lr = y_test - y_pred_lr\nresiduals_rf = y_test - y_pred_rf\naxes[1, 0].hist(residuals_lr, bins=15, alpha=0.6, label='Linear', color='#3498db', edgecolor='black')\naxes[1, 0].hist(residuals_rf, bins=15, alpha=0.6, label='Random Forest', color='#2ecc71', edgecolor='black')\naxes[1, 0].set_xlabel('Prediction Error', fontsize=11, fontweight='bold')\naxes[1, 0].set_ylabel('Frequency', fontsize=11, fontweight='bold')\naxes[1, 0].set_title('Error Distribution', fontsize=12, fontweight='bold')\naxes[1, 0].legend()\naxes[1, 0].grid(alpha=0.3)\n\n# Metrics\nlr_rmse = np.sqrt(np.mean(residuals_lr**2))\nrf_rmse = np.sqrt(np.mean(residuals_rf**2))\nmetrics = ['R² Score', 'RMSE']\nx_pos = np.arange(len(metrics))\naxes[1, 1].bar(x_pos - 0.175, [lr_test_r2, lr_rmse], 0.35, label='Linear', color='#3498db')\naxes[1, 1].bar(x_pos + 0.175, [rf_test_r2, rf_rmse], 0.35, label='Random Forest', color='#2ecc71')\naxes[1, 1].set_xticks(x_pos)\naxes[1, 1].set_xticklabels(metrics, fontsize=11, fontweight='bold')\naxes[1, 1].set_ylabel('Value', fontsize=11, fontweight='bold')\naxes[1, 1].set_title('Performance Metrics', fontsize=12, fontweight='bold')\naxes[1, 1].legend()\naxes[1, 1].grid(axis='y', alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"Random Forest performs better (R² = {rf_test_r2:.4f})\")\nprint(f\"Linear Regression performs  (R² = {lr_test_r2:.4f})\")\n\n\n\n\n\n\n\n\nRandom Forest performs better (R² = 0.9142)\nLinear Regression performs  (R² = 0.9082)\n\n\nThe combined figure summarizes how well both linear regression and random forest models predict life expectancy. Both approaches fit the data closely, as seen by the strong alignment of predictions with actual values and R² scores near 0.91. Most errors cluster around zero, and random forest achieves the lowest average error, confirming consistent accuracy. The side-by-side bar plot and error histogram highlight the slight but clear edge that random forest has over linear regression for this task. Together, these visuals show that health and economic features are highly effective for estimating national life expectancy."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Global Health: COVID & Economic Context",
    "section": "",
    "text": "Project Overview\nThis project analyzes global health outcomes using the Google Cloud COVID-19 Open Data and enriches it with macroeconomic indicators from the World Bank API (e.g., GDP per capita).\nWe document:\n\nData retrieval: automated download of health data and World Bank indicators\n\nData enrichment & cleaning: constructing tidy health and economic_data tables, then merging into a combined df_clean\n\nVisualization: interactive charts and tables exploring relationships between health outcomes and economic variables\n\n\n\nNavigation\nUse the top navigation bar to explore:\n\nData Prep: how we retrieved and cleaned the raw data\n\nAnalysis: visualizations and insights\n\n\n\nExample interactive widget (placeholder)\nBelow is an example of where an interactive widget (e.g., Plotly chart or itables) can go:\nimport plotly.express as px import pandas as pd\n\n\nTiny demo dataset – replace with a real subset of your df_clean\ndemo = pd.DataFrame({ “country”: [“A”, “B”, “C”, “D”], “gdp_per_capita_usd”: [1000, 5000, 15000, 25000], “cases_per_100k”: [200, 800, 1200, 400] })\nfig = px.scatter( demo, x=“gdp_per_capita_usd”, y=“cases_per_100k”, hover_name=“country”, title=“Demo: GDP per Capita vs Cases per 100k” ) fig"
  },
  {
    "objectID": "retrieval.html",
    "href": "retrieval.html",
    "title": "GLOBAL HEALTH DATA ANALYSIS - Data Retrieval and Sources",
    "section": "",
    "text": "# Mount Google Drive\n#from google.colab import drive\n#drive.mount('/content/drive')\n\nImporting required libraries\n\n# Importing all required libraries\nimport pandas as pd\nimport numpy as np\nimport requests\nimport json\nfrom io import StringIO\n\nSetting Database Link from WHO\n\nhealth_url = \"https://storage.googleapis.com/covid19-open-data/v3/health.csv\"\n\n\ntry:\n    response = requests.get(health_url, timeout=10)\n    response.raise_for_status()  # Raises HTTPError for bad responses\n    health = pd.read_csv(StringIO(response.text))\n    print(\"Data successfully retrieved!\")\nexcept Exception as e:\n    print(\"Error retrieving data:\", e)\n\nhealth.head()\n\nData successfully retrieved!\n\n\n\n\n\n\n\n\n\nlocation_key\nlife_expectancy\nsmoking_prevalence\ndiabetes_prevalence\ninfant_mortality_rate\nadult_male_mortality_rate\nadult_female_mortality_rate\npollution_mortality_rate\ncomorbidity_mortality_rate\nhospital_beds_per_1000\nnurses_per_1000\nphysicians_per_1000\nhealth_expenditure_usd\nout_of_pocket_health_expenditure_usd\n\n\n\n\n0\nAD\nNaN\n33.5\n7.7\n2.7\nNaN\nNaN\nNaN\nNaN\nNaN\n4.0128\n3.3333\n4040.786621\n1688.121460\n\n\n1\nAE\n77.814\n28.9\n16.3\n6.5\n69.555\n44.863\n54.7\n16.8\nNaN\n5.7271\n2.5278\n1357.017456\n256.034485\n\n\n2\nAF\n64.486\nNaN\n9.2\n47.9\n237.554\n192.532\n211.1\n29.8\n0.5\n0.1755\n0.2782\n67.122650\n50.665913\n\n\n3\nAG\n76.885\nNaN\n13.1\n5.0\n126.917\n83.136\n29.9\n22.6\nNaN\n4.5171\n2.9560\n673.859680\n235.749039\n\n\n4\nAL\n78.900\n28.7\n9.0\n7.8\n93.315\n49.486\n68.0\n17.0\nNaN\n3.6495\n1.2164\nNaN\nNaN\n\n\n\n\n\n\n\n\n# === 2, \nHEALTH_URL = \"https://storage.googleapis.com/covid19-open-data/v3/health.csv\"\n\nprint(f\"Downloading health data from: {HEALTH_URL}\")\nhealth = pd.read_csv(HEALTH_URL)\n\nprint(\"✓ Raw Data Loaded from remote health.csv\")\nprint(f\"  Shape: {health.shape[0]:,} rows × {health.shape[1]} columns\")\nprint(f\"  Columns: {list(health.columns)[:10]} ...\\n\")\n\n# Extract UNIQUE country codes (no subdivisions)\ncountries = (\n    health.loc[~health[\"location_key\"].str.contains(\"_\", na=False), \"location_key\"]\n    .dropna()\n    .unique()\n)\n\nprint(f\"✓ Extracted {len(countries)} country codes for API enrichment\")\nprint(\"  Sample:\", \", \".join(countries[:10]), \"\\n\")\n\nDownloading health data from: https://storage.googleapis.com/covid19-open-data/v3/health.csv\n✓ Raw Data Loaded from remote health.csv\n  Shape: 3,504 rows × 14 columns\n  Columns: ['location_key', 'life_expectancy', 'smoking_prevalence', 'diabetes_prevalence', 'infant_mortality_rate', 'adult_male_mortality_rate', 'adult_female_mortality_rate', 'pollution_mortality_rate', 'comorbidity_mortality_rate', 'hospital_beds_per_1000'] ...\n\n✓ Extracted 209 country codes for API enrichment\n  Sample: AD, AE, AF, AG, AL, AM, AO, AR, AT, AU \n\n\n\n\n\n# === 2. World Bank API setup ===\nprint(\"Endpoint: https://api.worldbank.org/v2/\")\n\nINDICATORS = {\n    'NY.GDP.MKTP.CD': 'GDP (current US$)',\n    'NY.GDP.PCAP.CD': 'GDP per capita (current US$)',\n    'SL.UEM.TOTL.ZS': 'Unemployment rate (% of labor force)',\n    'NY.GDP.MKTP.KD': 'GDP (constant 2015 US$)'\n}\n\nTARGET_YEAR = \"2022\"\nGDP_PER_CAPITA_INDICATOR = \"NY.GDP.PCAP.CD\"\n\neconomic_data_list = []\n\ntry:\n    print(\"Attempting to fetch REAL data from World Bank API...\\n\")\n\n    # Try to fetch data for each country\n    for country_code in countries:\n        try:\n            # Fetch GDP per capita indicator (REAL data)\n            gdp_url = (\n                f\"https://api.worldbank.org/v2/country/\"\n                f\"{country_code}/indicators/{GDP_PER_CAPITA_INDICATOR}\"\n                f\"?format=json&date={TARGET_YEAR}\"\n            )\n\n            print(f\"  {country_code}: Connecting to API... \", end=\"\")\n            gdp_response = requests.get(gdp_url, timeout=60)\n\n            if gdp_response.status_code == 200:\n                gdp_data = gdp_response.json()\n\n                # Extract REAL values from API response\n                if gdp_data and len(gdp_data) &gt; 1 and gdp_data[1]:\n                    # Get the most recent data point\n                    data_point = gdp_data[1][0]\n                    gdp_value = data_point.get(\"value\")\n\n                    if gdp_value is not None:  # Only if we got REAL data\n                        economic_data_list.append({\n                            \"location_key\": country_code,\n                            \"gdp_per_capita_usd\": float(gdp_value),\n                            \"data_year\": data_point.get(\"date\"),\n                            \"source\": \"World Bank API (REAL DATA)\",\n                        })\n                        print(f\"✓ Got REAL data: ${float(gdp_value):,.0f}\")\n                    else:\n                        print(\"✗ No value in response\")\n                else:\n                    print(\"✗ Empty response\")\n            else:\n                print(f\"✗ Status {gdp_response.status_code}\")\n\n        except requests.exceptions.Timeout:\n            print(\"⚠ Timeout\")\n        except Exception as e:\n            print(f\"✗ Error ({str(e)[:40]})\")\n\nexcept Exception as e:\n    print(f\"⚠ API Error: {str(e)[:50]}\")\n\n# Create DataFrame from fetched data\nif economic_data_list:\n    economic_data = pd.DataFrame(economic_data_list)\n    print(f\"\\nSuccessfully retrieved {len(economic_data)} countries with REAL World Bank data!\")\n    print(\"\\n   Sample:\")\n    print(economic_data[[\"location_key\", \"gdp_per_capita_usd\", \"data_year\"]].head())\nelse:\n    print(\"\\n⚠ No REAL data retrieved from API\")\n    print(\"   Creating empty DataFrame...\")\n    economic_data = pd.DataFrame({\n        \"location_key\": countries[:5],\n        \"gdp_per_capita_usd\": [np.nan] * 5,\n        \"source\": \"World Bank API (Attempted - No Data Retrieved)\",\n    })\n\nEndpoint: https://api.worldbank.org/v2/\nAttempting to fetch REAL data from World Bank API...\n\n  AD: Connecting to API... ✓ Got REAL data: $42,414\n  AE: Connecting to API... ✓ Got REAL data: $49,899\n  AF: Connecting to API... ✓ Got REAL data: $357\n  AG: Connecting to API... ✓ Got REAL data: $20,105\n  AL: Connecting to API... ✓ Got REAL data: $6,846\n  AM: Connecting to API... ✓ Got REAL data: $6,572\n  AO: Connecting to API... ✗ Status 400\n  AR: Connecting to API... ✓ Got REAL data: $13,936\n  AT: Connecting to API... ✓ Got REAL data: $52,177\n  AU: Connecting to API... ✓ Got REAL data: $64,997\n  AW: Connecting to API... ✗ Status 400\n  AZ: Connecting to API... ✗ Status 400\n  BA: Connecting to API... ✗ Status 400\n  BB: Connecting to API... ✗ Status 400\n  BD: Connecting to API... ✗ Status 400\n  BE: Connecting to API... ✓ Got REAL data: $50,822\n  BF: Connecting to API... ✓ Got REAL data: $836\n  BG: Connecting to API... ✓ Got REAL data: $14,000\n  BH: Connecting to API... ✓ Got REAL data: $30,471\n  BI: Connecting to API... ✓ Got REAL data: $251\n  BJ: Connecting to API... ✓ Got REAL data: $1,266\n  BM: Connecting to API... ✗ Status 400\n  BN: Connecting to API... ✗ Status 400\n  BO: Connecting to API... ✗ Status 400\n  BR: Connecting to API... ✓ Got REAL data: $9,281\n  BS: Connecting to API... ✓ Got REAL data: $34,957\n  BT: Connecting to API... ✓ Got REAL data: $3,711\n  BW: Connecting to API... ✓ Got REAL data: $8,329\n  BY: Connecting to API... ✓ Got REAL data: $7,995\n  BZ: Connecting to API... ✗ Status 400\n  CA: Connecting to API... ✓ Got REAL data: $56,257\n  CD: Connecting to API... ✗ Status 400\n  CF: Connecting to API... ✓ Got REAL data: $467\n  CG: Connecting to API... ✓ Got REAL data: $2,621\n  CH: Connecting to API... ✗ Status 400\n  CI: Connecting to API... ✗ Status 400\n  CL: Connecting to API... ✓ Got REAL data: $15,406\n  CM: Connecting to API... ✗ Status 400\n  CN: Connecting to API... ✓ Got REAL data: $12,971\n  CO: Connecting to API... ✓ Got REAL data: $6,680\n  CR: Connecting to API... ✓ Got REAL data: $13,626\n  CU: Connecting to API... ✗ Status 400\n  CV: Connecting to API... ✓ Got REAL data: $4,323\n  CW: Connecting to API... ✗ Status 400\n  CY: Connecting to API... ✗ Status 400\n  CZ: Connecting to API... ✗ Status 400\n  DE: Connecting to API... ✗ Status 400\n  DJ: Connecting to API... ✓ Got REAL data: $3,133\n  DK: Connecting to API... ✓ Got REAL data: $68,091\n  DM: Connecting to API... ✓ Got REAL data: $9,324\n  DO: Connecting to API... ✗ Status 400\n  DZ: Connecting to API... ✗ Status 400\n  EC: Connecting to API... ✗ Status 400\n  EE: Connecting to API... ✗ Status 400\n  EG: Connecting to API... ✗ Status 400\n  ER: Connecting to API... ✗ Status 400\n  ES: Connecting to API... ✗ Status 400\n  ET: Connecting to API... ✗ Status 400\n  FI: Connecting to API... ✓ Got REAL data: $50,441\n  FJ: Connecting to API... ✗ Status 400\n  FM: Connecting to API... ✗ Status 400\n  FO: Connecting to API... ✓ Got REAL data: $66,139\n  FR: Connecting to API... ✓ Got REAL data: $41,083\n  GA: Connecting to API... ✓ Got REAL data: $8,409\n  GB: Connecting to API... ✓ Got REAL data: $46,063\n  GD: Connecting to API... ✓ Got REAL data: $10,535\n  GE: Connecting to API... ✓ Got REAL data: $6,730\n  GH: Connecting to API... ✓ Got REAL data: $2,230\n  GL: Connecting to API... ✓ Got REAL data: $55,635\n  GM: Connecting to API... ✗ Status 400\n  GN: Connecting to API... ✓ Got REAL data: $1,417\n  GQ: Connecting to API... ✗ Status 400\n  GR: Connecting to API... ✓ Got REAL data: $20,972\n  GT: Connecting to API... ✓ Got REAL data: $5,359\n  GU: Connecting to API... ✗ Status 400\n  GW: Connecting to API... ✓ Got REAL data: $873\n  GY: Connecting to API... ✓ Got REAL data: $17,913\n  HK: Connecting to API... ✓ Got REAL data: $48,826\n  HN: Connecting to API... ✓ Got REAL data: $3,003\n  HR: Connecting to API... ⚠ Timeout\n  HT: Connecting to API... ✓ Got REAL data: $1,761\n  HU: Connecting to API... ✓ Got REAL data: $18,484\n  ID: Connecting to API... ✓ Got REAL data: $4,731\n  IE: Connecting to API... ✓ Got REAL data: $105,235\n  IL: Connecting to API... ✓ Got REAL data: $54,950\n  IM: Connecting to API... ✓ Got REAL data: $88,329\n  IN: Connecting to API... ✓ Got REAL data: $2,347\n  IQ: Connecting to API... ✓ Got REAL data: $6,521\n  IR: Connecting to API... ✓ Got REAL data: $4,405\n  IS: Connecting to API... ⚠ Timeout\n  IT: Connecting to API... ✓ Got REAL data: $35,654\n  JM: Connecting to API... ✓ Got REAL data: $6,022\n  JO: Connecting to API... ✓ Got REAL data: $4,332\n  JP: Connecting to API... ✓ Got REAL data: $34,066\n  KE: Connecting to API... ✓ Got REAL data: $2,110\n  KG: Connecting to API... ✓ Got REAL data: $1,740\n  KH: Connecting to API... ✓ Got REAL data: $2,325\n  KI: Connecting to API... ✓ Got REAL data: $2,070\n  KM: Connecting to API... ✓ Got REAL data: $1,534\n  KN: Connecting to API... ✓ Got REAL data: $20,985\n  KP: Connecting to API... ✗ No value in response\n  KR: Connecting to API... ✓ Got REAL data: $32,395\n  KW: Connecting to API... ✓ Got REAL data: $39,982\n  KY: Connecting to API... ✓ Got REAL data: $92,202\n  KZ: Connecting to API... ✓ Got REAL data: $11,255\n  LA: Connecting to API... ✓ Got REAL data: $2,046\n  LB: Connecting to API... ✓ Got REAL data: $3,654\n  LC: Connecting to API... ✓ Got REAL data: $13,104\n  LI: Connecting to API... ✓ Got REAL data: $186,822\n  LK: Connecting to API... ✓ Got REAL data: $3,343\n  LR: Connecting to API... ✓ Got REAL data: $745\n  LS: Connecting to API... ✓ Got REAL data: $1,030\n  LT: Connecting to API... ⚠ Timeout\n  LU: Connecting to API... ⚠ Timeout\n  LV: Connecting to API... ✓ Got REAL data: $20,227\n  LY: Connecting to API... ✓ Got REAL data: $5,987\n  MA: Connecting to API... ✓ Got REAL data: $3,455\n  MC: Connecting to API... ✓ Got REAL data: $226,052\n  MD: Connecting to API... ✓ Got REAL data: $5,744\n  ME: Connecting to API... ✓ Got REAL data: $9,990\n  MG: Connecting to API... ✓ Got REAL data: $504\n  MH: Connecting to API... ✓ Got REAL data: $6,323\n  MK: Connecting to API... ✓ Got REAL data: $7,606\n  ML: Connecting to API... ✓ Got REAL data: $970\n  MM: Connecting to API... ✓ Got REAL data: $1,158\n  MN: Connecting to API... ✓ Got REAL data: $4,994\n  MO: Connecting to API... ✓ Got REAL data: $36,910\n  MR: Connecting to API... ✓ Got REAL data: $1,960\n  MT: Connecting to API... ✓ Got REAL data: $36,224\n  MU: Connecting to API... ✓ Got REAL data: $10,224\n  MV: Connecting to API... ✓ Got REAL data: $11,786\n  MW: Connecting to API... ⚠ Timeout\n  MX: Connecting to API... ✓ Got REAL data: $11,402\n  MY: Connecting to API... ✓ Got REAL data: $11,748\n  MZ: Connecting to API... ⚠ Timeout\n  NC: Connecting to API... ✓ Got REAL data: $33,516\n  NE: Connecting to API... ✓ Got REAL data: $610\n  NG: Connecting to API... ✓ Got REAL data: $2,139\n  NI: Connecting to API... ✓ Got REAL data: $2,323\n  NL: Connecting to API... ✓ Got REAL data: $59,123\n  NO: Connecting to API... ✓ Got REAL data: $109,270\n  NP: Connecting to API... ✓ Got REAL data: $1,386\n  NR: Connecting to API... ✓ Got REAL data: $12,896\n  NZ: Connecting to API... ✓ Got REAL data: $48,760\n  OM: Connecting to API... ✓ Got REAL data: $23,224\n  PA: Connecting to API... ✓ Got REAL data: $17,332\n  PE: Connecting to API... ✓ Got REAL data: $7,351\n  PF: Connecting to API... ✓ Got REAL data: $20,739\n  PG: Connecting to API... ✓ Got REAL data: $3,102\n  PH: Connecting to API... ⚠ Timeout\n  PK: Connecting to API... ✓ Got REAL data: $1,538\n  PL: Connecting to API... ✓ Got REAL data: $18,891\n  PR: Connecting to API... ✓ Got REAL data: $35,354\n  PS: Connecting to API... ✓ Got REAL data: $3,800\n  PT: Connecting to API... ✓ Got REAL data: $24,621\n  PW: Connecting to API... ✓ Got REAL data: $14,392\n  PY: Connecting to API... ✓ Got REAL data: $6,206\n  QA: Connecting to API... ✓ Got REAL data: $88,701\n  RO: Connecting to API... ⚠ Timeout\n  RS: Connecting to API... ✓ Got REAL data: $10,023\n  RU: Connecting to API... ✓ Got REAL data: $15,620\n  RW: Connecting to API... ⚠ Timeout\n  SA: Connecting to API... ✓ Got REAL data: $38,510\n  SB: Connecting to API... ✓ Got REAL data: $2,005\n  SC: Connecting to API... ✓ Got REAL data: $16,837\n  SD: Connecting to API... ✓ Got REAL data: $1,046\n  SE: Connecting to API... ✓ Got REAL data: $55,297\n  SG: Connecting to API... ✓ Got REAL data: $90,299\n  SI: Connecting to API... ✓ Got REAL data: $28,374\n  SK: Connecting to API... ✓ Got REAL data: $21,335\n  SL: Connecting to API... ✗ Status 503\n  SM: Connecting to API... ✓ Got REAL data: $54,265\n  SN: Connecting to API... ✓ Got REAL data: $1,574\n  SO: Connecting to API... ✓ Got REAL data: $573\n  SR: Connecting to API... ✗ Status 400\n  SS: Connecting to API... ✗ No value in response\n  ST: Connecting to API... ✗ Status 400\n  SV: Connecting to API... ✓ Got REAL data: $5,075\n  SX: Connecting to API... ✓ Got REAL data: $36,477\n  SY: Connecting to API... ✓ Got REAL data: $1,052\n  SZ: Connecting to API... ✓ Got REAL data: $3,890\n  TD: Connecting to API... ✓ Got REAL data: $966\n  TG: Connecting to API... ✓ Got REAL data: $899\n  TH: Connecting to API... ✓ Got REAL data: $6,909\n  TJ: Connecting to API... ✓ Got REAL data: $1,052\n  TL: Connecting to API... ✓ Got REAL data: $2,343\n  TM: Connecting to API... ✓ Got REAL data: $8,156\n  TN: Connecting to API... ✓ Got REAL data: $3,709\n  TO: Connecting to API... ✓ Got REAL data: $4,933\n  TR: Connecting to API... ✓ Got REAL data: $10,675\n  TT: Connecting to API... ✓ Got REAL data: $20,874\n  TV: Connecting to API... ✓ Got REAL data: $5,911\n  TZ: Connecting to API... ✓ Got REAL data: $1,208\n  UA: Connecting to API... ⚠ Timeout\n  UG: Connecting to API... ✓ Got REAL data: $963\n  US: Connecting to API... ✓ Got REAL data: $77,861\n  UY: Connecting to API... ✓ Got REAL data: $20,819\n  UZ: Connecting to API... ✓ Got REAL data: $2,579\n  VC: Connecting to API... ✓ Got REAL data: $9,694\n  VE: Connecting to API... ✗ No value in response\n  VG: Connecting to API... ✗ No value in response\n  VI: Connecting to API... ✓ Got REAL data: $44,321\n  VN: Connecting to API... ✓ Got REAL data: $4,148\n  VU: Connecting to API... ✓ Got REAL data: $3,292\n  WS: Connecting to API... ✓ Got REAL data: $3,869\n  YE: Connecting to API... ✗ No value in response\n  ZA: Connecting to API... ✓ Got REAL data: $6,523\n  ZM: Connecting to API... ✗ Status 400\n  ZW: Connecting to API... ✓ Got REAL data: $2,041\n\nSuccessfully retrieved 158 countries with REAL World Bank data!\n\n   Sample:\n  location_key  gdp_per_capita_usd data_year\n0           AD        42414.059009      2022\n1           AE        49899.065298      2022\n2           AF          357.261153      2022\n3           AG        20105.198909      2022\n4           AL         6846.426694      2022\n\n\n\n# === 3. MERGE INTO CLEAN DATAFRAME ===\n\ndf_clean = health.merge(economic_data, how=\"left\", on=\"location_key\")\nprint(f\"✓ Combined dataset: {df_clean.shape[0]:,} rows, {df_clean.shape[1]} columns\\n\")\n\n\n# === 4. SAVE FILES TO GOOGLE DRIVE ===\n\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\nSAVE_DIR = \"/content/drive/MyDrive/global_health_project/\"\n\nhealth.to_csv(SAVE_DIR + \"health.csv\", index=False)\neconomic_data.to_csv(SAVE_DIR + \"economic_data.csv\", index=False)\ndf_clean.to_csv(SAVE_DIR + \"df_clean.csv\", index=False)\n\nprint(\"✓ Saved files to Google Drive successfully!\")\n\n\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[13], line 1\n----&gt; 1 from google.colab import drive\n      2 drive.mount('/content/drive')\n      4 SAVE_DIR = \"/content/drive/MyDrive/global_health_project/\"\n\nModuleNotFoundError: No module named 'google.colab'"
  },
  {
    "objectID": "retrieval.html#mount-google-drive-import-libraries",
    "href": "retrieval.html#mount-google-drive-import-libraries",
    "title": "GLOBAL HEALTH DATA ANALYSIS - Data Retrieval and Sources",
    "section": "",
    "text": "# Mount Google Drive\n#from google.colab import drive\n#drive.mount('/content/drive')\n\nImporting required libraries\n\n# Importing all required libraries\nimport pandas as pd\nimport numpy as np\nimport requests\nimport json\nfrom io import StringIO\n\nSetting Database Link from WHO\n\nhealth_url = \"https://storage.googleapis.com/covid19-open-data/v3/health.csv\"\n\n\ntry:\n    response = requests.get(health_url, timeout=10)\n    response.raise_for_status()  # Raises HTTPError for bad responses\n    health = pd.read_csv(StringIO(response.text))\n    print(\"Data successfully retrieved!\")\nexcept Exception as e:\n    print(\"Error retrieving data:\", e)\n\nhealth.head()\n\nData successfully retrieved!\n\n\n\n\n\n\n\n\n\nlocation_key\nlife_expectancy\nsmoking_prevalence\ndiabetes_prevalence\ninfant_mortality_rate\nadult_male_mortality_rate\nadult_female_mortality_rate\npollution_mortality_rate\ncomorbidity_mortality_rate\nhospital_beds_per_1000\nnurses_per_1000\nphysicians_per_1000\nhealth_expenditure_usd\nout_of_pocket_health_expenditure_usd\n\n\n\n\n0\nAD\nNaN\n33.5\n7.7\n2.7\nNaN\nNaN\nNaN\nNaN\nNaN\n4.0128\n3.3333\n4040.786621\n1688.121460\n\n\n1\nAE\n77.814\n28.9\n16.3\n6.5\n69.555\n44.863\n54.7\n16.8\nNaN\n5.7271\n2.5278\n1357.017456\n256.034485\n\n\n2\nAF\n64.486\nNaN\n9.2\n47.9\n237.554\n192.532\n211.1\n29.8\n0.5\n0.1755\n0.2782\n67.122650\n50.665913\n\n\n3\nAG\n76.885\nNaN\n13.1\n5.0\n126.917\n83.136\n29.9\n22.6\nNaN\n4.5171\n2.9560\n673.859680\n235.749039\n\n\n4\nAL\n78.900\n28.7\n9.0\n7.8\n93.315\n49.486\n68.0\n17.0\nNaN\n3.6495\n1.2164\nNaN\nNaN\n\n\n\n\n\n\n\n\n# === 2, \nHEALTH_URL = \"https://storage.googleapis.com/covid19-open-data/v3/health.csv\"\n\nprint(f\"Downloading health data from: {HEALTH_URL}\")\nhealth = pd.read_csv(HEALTH_URL)\n\nprint(\"✓ Raw Data Loaded from remote health.csv\")\nprint(f\"  Shape: {health.shape[0]:,} rows × {health.shape[1]} columns\")\nprint(f\"  Columns: {list(health.columns)[:10]} ...\\n\")\n\n# Extract UNIQUE country codes (no subdivisions)\ncountries = (\n    health.loc[~health[\"location_key\"].str.contains(\"_\", na=False), \"location_key\"]\n    .dropna()\n    .unique()\n)\n\nprint(f\"✓ Extracted {len(countries)} country codes for API enrichment\")\nprint(\"  Sample:\", \", \".join(countries[:10]), \"\\n\")\n\nDownloading health data from: https://storage.googleapis.com/covid19-open-data/v3/health.csv\n✓ Raw Data Loaded from remote health.csv\n  Shape: 3,504 rows × 14 columns\n  Columns: ['location_key', 'life_expectancy', 'smoking_prevalence', 'diabetes_prevalence', 'infant_mortality_rate', 'adult_male_mortality_rate', 'adult_female_mortality_rate', 'pollution_mortality_rate', 'comorbidity_mortality_rate', 'hospital_beds_per_1000'] ...\n\n✓ Extracted 209 country codes for API enrichment\n  Sample: AD, AE, AF, AG, AL, AM, AO, AR, AT, AU \n\n\n\n\n\n# === 2. World Bank API setup ===\nprint(\"Endpoint: https://api.worldbank.org/v2/\")\n\nINDICATORS = {\n    'NY.GDP.MKTP.CD': 'GDP (current US$)',\n    'NY.GDP.PCAP.CD': 'GDP per capita (current US$)',\n    'SL.UEM.TOTL.ZS': 'Unemployment rate (% of labor force)',\n    'NY.GDP.MKTP.KD': 'GDP (constant 2015 US$)'\n}\n\nTARGET_YEAR = \"2022\"\nGDP_PER_CAPITA_INDICATOR = \"NY.GDP.PCAP.CD\"\n\neconomic_data_list = []\n\ntry:\n    print(\"Attempting to fetch REAL data from World Bank API...\\n\")\n\n    # Try to fetch data for each country\n    for country_code in countries:\n        try:\n            # Fetch GDP per capita indicator (REAL data)\n            gdp_url = (\n                f\"https://api.worldbank.org/v2/country/\"\n                f\"{country_code}/indicators/{GDP_PER_CAPITA_INDICATOR}\"\n                f\"?format=json&date={TARGET_YEAR}\"\n            )\n\n            print(f\"  {country_code}: Connecting to API... \", end=\"\")\n            gdp_response = requests.get(gdp_url, timeout=60)\n\n            if gdp_response.status_code == 200:\n                gdp_data = gdp_response.json()\n\n                # Extract REAL values from API response\n                if gdp_data and len(gdp_data) &gt; 1 and gdp_data[1]:\n                    # Get the most recent data point\n                    data_point = gdp_data[1][0]\n                    gdp_value = data_point.get(\"value\")\n\n                    if gdp_value is not None:  # Only if we got REAL data\n                        economic_data_list.append({\n                            \"location_key\": country_code,\n                            \"gdp_per_capita_usd\": float(gdp_value),\n                            \"data_year\": data_point.get(\"date\"),\n                            \"source\": \"World Bank API (REAL DATA)\",\n                        })\n                        print(f\"✓ Got REAL data: ${float(gdp_value):,.0f}\")\n                    else:\n                        print(\"✗ No value in response\")\n                else:\n                    print(\"✗ Empty response\")\n            else:\n                print(f\"✗ Status {gdp_response.status_code}\")\n\n        except requests.exceptions.Timeout:\n            print(\"⚠ Timeout\")\n        except Exception as e:\n            print(f\"✗ Error ({str(e)[:40]})\")\n\nexcept Exception as e:\n    print(f\"⚠ API Error: {str(e)[:50]}\")\n\n# Create DataFrame from fetched data\nif economic_data_list:\n    economic_data = pd.DataFrame(economic_data_list)\n    print(f\"\\nSuccessfully retrieved {len(economic_data)} countries with REAL World Bank data!\")\n    print(\"\\n   Sample:\")\n    print(economic_data[[\"location_key\", \"gdp_per_capita_usd\", \"data_year\"]].head())\nelse:\n    print(\"\\n⚠ No REAL data retrieved from API\")\n    print(\"   Creating empty DataFrame...\")\n    economic_data = pd.DataFrame({\n        \"location_key\": countries[:5],\n        \"gdp_per_capita_usd\": [np.nan] * 5,\n        \"source\": \"World Bank API (Attempted - No Data Retrieved)\",\n    })\n\nEndpoint: https://api.worldbank.org/v2/\nAttempting to fetch REAL data from World Bank API...\n\n  AD: Connecting to API... ✓ Got REAL data: $42,414\n  AE: Connecting to API... ✓ Got REAL data: $49,899\n  AF: Connecting to API... ✓ Got REAL data: $357\n  AG: Connecting to API... ✓ Got REAL data: $20,105\n  AL: Connecting to API... ✓ Got REAL data: $6,846\n  AM: Connecting to API... ✓ Got REAL data: $6,572\n  AO: Connecting to API... ✗ Status 400\n  AR: Connecting to API... ✓ Got REAL data: $13,936\n  AT: Connecting to API... ✓ Got REAL data: $52,177\n  AU: Connecting to API... ✓ Got REAL data: $64,997\n  AW: Connecting to API... ✗ Status 400\n  AZ: Connecting to API... ✗ Status 400\n  BA: Connecting to API... ✗ Status 400\n  BB: Connecting to API... ✗ Status 400\n  BD: Connecting to API... ✗ Status 400\n  BE: Connecting to API... ✓ Got REAL data: $50,822\n  BF: Connecting to API... ✓ Got REAL data: $836\n  BG: Connecting to API... ✓ Got REAL data: $14,000\n  BH: Connecting to API... ✓ Got REAL data: $30,471\n  BI: Connecting to API... ✓ Got REAL data: $251\n  BJ: Connecting to API... ✓ Got REAL data: $1,266\n  BM: Connecting to API... ✗ Status 400\n  BN: Connecting to API... ✗ Status 400\n  BO: Connecting to API... ✗ Status 400\n  BR: Connecting to API... ✓ Got REAL data: $9,281\n  BS: Connecting to API... ✓ Got REAL data: $34,957\n  BT: Connecting to API... ✓ Got REAL data: $3,711\n  BW: Connecting to API... ✓ Got REAL data: $8,329\n  BY: Connecting to API... ✓ Got REAL data: $7,995\n  BZ: Connecting to API... ✗ Status 400\n  CA: Connecting to API... ✓ Got REAL data: $56,257\n  CD: Connecting to API... ✗ Status 400\n  CF: Connecting to API... ✓ Got REAL data: $467\n  CG: Connecting to API... ✓ Got REAL data: $2,621\n  CH: Connecting to API... ✗ Status 400\n  CI: Connecting to API... ✗ Status 400\n  CL: Connecting to API... ✓ Got REAL data: $15,406\n  CM: Connecting to API... ✗ Status 400\n  CN: Connecting to API... ✓ Got REAL data: $12,971\n  CO: Connecting to API... ✓ Got REAL data: $6,680\n  CR: Connecting to API... ✓ Got REAL data: $13,626\n  CU: Connecting to API... ✗ Status 400\n  CV: Connecting to API... ✓ Got REAL data: $4,323\n  CW: Connecting to API... ✗ Status 400\n  CY: Connecting to API... ✗ Status 400\n  CZ: Connecting to API... ✗ Status 400\n  DE: Connecting to API... ✗ Status 400\n  DJ: Connecting to API... ✓ Got REAL data: $3,133\n  DK: Connecting to API... ✓ Got REAL data: $68,091\n  DM: Connecting to API... ✓ Got REAL data: $9,324\n  DO: Connecting to API... ✗ Status 400\n  DZ: Connecting to API... ✗ Status 400\n  EC: Connecting to API... ✗ Status 400\n  EE: Connecting to API... ✗ Status 400\n  EG: Connecting to API... ✗ Status 400\n  ER: Connecting to API... ✗ Status 400\n  ES: Connecting to API... ✗ Status 400\n  ET: Connecting to API... ✗ Status 400\n  FI: Connecting to API... ✓ Got REAL data: $50,441\n  FJ: Connecting to API... ✗ Status 400\n  FM: Connecting to API... ✗ Status 400\n  FO: Connecting to API... ✓ Got REAL data: $66,139\n  FR: Connecting to API... ✓ Got REAL data: $41,083\n  GA: Connecting to API... ✓ Got REAL data: $8,409\n  GB: Connecting to API... ✓ Got REAL data: $46,063\n  GD: Connecting to API... ✓ Got REAL data: $10,535\n  GE: Connecting to API... ✓ Got REAL data: $6,730\n  GH: Connecting to API... ✓ Got REAL data: $2,230\n  GL: Connecting to API... ✓ Got REAL data: $55,635\n  GM: Connecting to API... ✗ Status 400\n  GN: Connecting to API... ✓ Got REAL data: $1,417\n  GQ: Connecting to API... ✗ Status 400\n  GR: Connecting to API... ✓ Got REAL data: $20,972\n  GT: Connecting to API... ✓ Got REAL data: $5,359\n  GU: Connecting to API... ✗ Status 400\n  GW: Connecting to API... ✓ Got REAL data: $873\n  GY: Connecting to API... ✓ Got REAL data: $17,913\n  HK: Connecting to API... ✓ Got REAL data: $48,826\n  HN: Connecting to API... ✓ Got REAL data: $3,003\n  HR: Connecting to API... ⚠ Timeout\n  HT: Connecting to API... ✓ Got REAL data: $1,761\n  HU: Connecting to API... ✓ Got REAL data: $18,484\n  ID: Connecting to API... ✓ Got REAL data: $4,731\n  IE: Connecting to API... ✓ Got REAL data: $105,235\n  IL: Connecting to API... ✓ Got REAL data: $54,950\n  IM: Connecting to API... ✓ Got REAL data: $88,329\n  IN: Connecting to API... ✓ Got REAL data: $2,347\n  IQ: Connecting to API... ✓ Got REAL data: $6,521\n  IR: Connecting to API... ✓ Got REAL data: $4,405\n  IS: Connecting to API... ⚠ Timeout\n  IT: Connecting to API... ✓ Got REAL data: $35,654\n  JM: Connecting to API... ✓ Got REAL data: $6,022\n  JO: Connecting to API... ✓ Got REAL data: $4,332\n  JP: Connecting to API... ✓ Got REAL data: $34,066\n  KE: Connecting to API... ✓ Got REAL data: $2,110\n  KG: Connecting to API... ✓ Got REAL data: $1,740\n  KH: Connecting to API... ✓ Got REAL data: $2,325\n  KI: Connecting to API... ✓ Got REAL data: $2,070\n  KM: Connecting to API... ✓ Got REAL data: $1,534\n  KN: Connecting to API... ✓ Got REAL data: $20,985\n  KP: Connecting to API... ✗ No value in response\n  KR: Connecting to API... ✓ Got REAL data: $32,395\n  KW: Connecting to API... ✓ Got REAL data: $39,982\n  KY: Connecting to API... ✓ Got REAL data: $92,202\n  KZ: Connecting to API... ✓ Got REAL data: $11,255\n  LA: Connecting to API... ✓ Got REAL data: $2,046\n  LB: Connecting to API... ✓ Got REAL data: $3,654\n  LC: Connecting to API... ✓ Got REAL data: $13,104\n  LI: Connecting to API... ✓ Got REAL data: $186,822\n  LK: Connecting to API... ✓ Got REAL data: $3,343\n  LR: Connecting to API... ✓ Got REAL data: $745\n  LS: Connecting to API... ✓ Got REAL data: $1,030\n  LT: Connecting to API... ⚠ Timeout\n  LU: Connecting to API... ⚠ Timeout\n  LV: Connecting to API... ✓ Got REAL data: $20,227\n  LY: Connecting to API... ✓ Got REAL data: $5,987\n  MA: Connecting to API... ✓ Got REAL data: $3,455\n  MC: Connecting to API... ✓ Got REAL data: $226,052\n  MD: Connecting to API... ✓ Got REAL data: $5,744\n  ME: Connecting to API... ✓ Got REAL data: $9,990\n  MG: Connecting to API... ✓ Got REAL data: $504\n  MH: Connecting to API... ✓ Got REAL data: $6,323\n  MK: Connecting to API... ✓ Got REAL data: $7,606\n  ML: Connecting to API... ✓ Got REAL data: $970\n  MM: Connecting to API... ✓ Got REAL data: $1,158\n  MN: Connecting to API... ✓ Got REAL data: $4,994\n  MO: Connecting to API... ✓ Got REAL data: $36,910\n  MR: Connecting to API... ✓ Got REAL data: $1,960\n  MT: Connecting to API... ✓ Got REAL data: $36,224\n  MU: Connecting to API... ✓ Got REAL data: $10,224\n  MV: Connecting to API... ✓ Got REAL data: $11,786\n  MW: Connecting to API... ⚠ Timeout\n  MX: Connecting to API... ✓ Got REAL data: $11,402\n  MY: Connecting to API... ✓ Got REAL data: $11,748\n  MZ: Connecting to API... ⚠ Timeout\n  NC: Connecting to API... ✓ Got REAL data: $33,516\n  NE: Connecting to API... ✓ Got REAL data: $610\n  NG: Connecting to API... ✓ Got REAL data: $2,139\n  NI: Connecting to API... ✓ Got REAL data: $2,323\n  NL: Connecting to API... ✓ Got REAL data: $59,123\n  NO: Connecting to API... ✓ Got REAL data: $109,270\n  NP: Connecting to API... ✓ Got REAL data: $1,386\n  NR: Connecting to API... ✓ Got REAL data: $12,896\n  NZ: Connecting to API... ✓ Got REAL data: $48,760\n  OM: Connecting to API... ✓ Got REAL data: $23,224\n  PA: Connecting to API... ✓ Got REAL data: $17,332\n  PE: Connecting to API... ✓ Got REAL data: $7,351\n  PF: Connecting to API... ✓ Got REAL data: $20,739\n  PG: Connecting to API... ✓ Got REAL data: $3,102\n  PH: Connecting to API... ⚠ Timeout\n  PK: Connecting to API... ✓ Got REAL data: $1,538\n  PL: Connecting to API... ✓ Got REAL data: $18,891\n  PR: Connecting to API... ✓ Got REAL data: $35,354\n  PS: Connecting to API... ✓ Got REAL data: $3,800\n  PT: Connecting to API... ✓ Got REAL data: $24,621\n  PW: Connecting to API... ✓ Got REAL data: $14,392\n  PY: Connecting to API... ✓ Got REAL data: $6,206\n  QA: Connecting to API... ✓ Got REAL data: $88,701\n  RO: Connecting to API... ⚠ Timeout\n  RS: Connecting to API... ✓ Got REAL data: $10,023\n  RU: Connecting to API... ✓ Got REAL data: $15,620\n  RW: Connecting to API... ⚠ Timeout\n  SA: Connecting to API... ✓ Got REAL data: $38,510\n  SB: Connecting to API... ✓ Got REAL data: $2,005\n  SC: Connecting to API... ✓ Got REAL data: $16,837\n  SD: Connecting to API... ✓ Got REAL data: $1,046\n  SE: Connecting to API... ✓ Got REAL data: $55,297\n  SG: Connecting to API... ✓ Got REAL data: $90,299\n  SI: Connecting to API... ✓ Got REAL data: $28,374\n  SK: Connecting to API... ✓ Got REAL data: $21,335\n  SL: Connecting to API... ✗ Status 503\n  SM: Connecting to API... ✓ Got REAL data: $54,265\n  SN: Connecting to API... ✓ Got REAL data: $1,574\n  SO: Connecting to API... ✓ Got REAL data: $573\n  SR: Connecting to API... ✗ Status 400\n  SS: Connecting to API... ✗ No value in response\n  ST: Connecting to API... ✗ Status 400\n  SV: Connecting to API... ✓ Got REAL data: $5,075\n  SX: Connecting to API... ✓ Got REAL data: $36,477\n  SY: Connecting to API... ✓ Got REAL data: $1,052\n  SZ: Connecting to API... ✓ Got REAL data: $3,890\n  TD: Connecting to API... ✓ Got REAL data: $966\n  TG: Connecting to API... ✓ Got REAL data: $899\n  TH: Connecting to API... ✓ Got REAL data: $6,909\n  TJ: Connecting to API... ✓ Got REAL data: $1,052\n  TL: Connecting to API... ✓ Got REAL data: $2,343\n  TM: Connecting to API... ✓ Got REAL data: $8,156\n  TN: Connecting to API... ✓ Got REAL data: $3,709\n  TO: Connecting to API... ✓ Got REAL data: $4,933\n  TR: Connecting to API... ✓ Got REAL data: $10,675\n  TT: Connecting to API... ✓ Got REAL data: $20,874\n  TV: Connecting to API... ✓ Got REAL data: $5,911\n  TZ: Connecting to API... ✓ Got REAL data: $1,208\n  UA: Connecting to API... ⚠ Timeout\n  UG: Connecting to API... ✓ Got REAL data: $963\n  US: Connecting to API... ✓ Got REAL data: $77,861\n  UY: Connecting to API... ✓ Got REAL data: $20,819\n  UZ: Connecting to API... ✓ Got REAL data: $2,579\n  VC: Connecting to API... ✓ Got REAL data: $9,694\n  VE: Connecting to API... ✗ No value in response\n  VG: Connecting to API... ✗ No value in response\n  VI: Connecting to API... ✓ Got REAL data: $44,321\n  VN: Connecting to API... ✓ Got REAL data: $4,148\n  VU: Connecting to API... ✓ Got REAL data: $3,292\n  WS: Connecting to API... ✓ Got REAL data: $3,869\n  YE: Connecting to API... ✗ No value in response\n  ZA: Connecting to API... ✓ Got REAL data: $6,523\n  ZM: Connecting to API... ✗ Status 400\n  ZW: Connecting to API... ✓ Got REAL data: $2,041\n\nSuccessfully retrieved 158 countries with REAL World Bank data!\n\n   Sample:\n  location_key  gdp_per_capita_usd data_year\n0           AD        42414.059009      2022\n1           AE        49899.065298      2022\n2           AF          357.261153      2022\n3           AG        20105.198909      2022\n4           AL         6846.426694      2022\n\n\n\n# === 3. MERGE INTO CLEAN DATAFRAME ===\n\ndf_clean = health.merge(economic_data, how=\"left\", on=\"location_key\")\nprint(f\"✓ Combined dataset: {df_clean.shape[0]:,} rows, {df_clean.shape[1]} columns\\n\")\n\n\n# === 4. SAVE FILES TO GOOGLE DRIVE ===\n\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\nSAVE_DIR = \"/content/drive/MyDrive/global_health_project/\"\n\nhealth.to_csv(SAVE_DIR + \"health.csv\", index=False)\neconomic_data.to_csv(SAVE_DIR + \"economic_data.csv\", index=False)\ndf_clean.to_csv(SAVE_DIR + \"df_clean.csv\", index=False)\n\nprint(\"✓ Saved files to Google Drive successfully!\")\n\n\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[13], line 1\n----&gt; 1 from google.colab import drive\n      2 drive.mount('/content/drive')\n      4 SAVE_DIR = \"/content/drive/MyDrive/global_health_project/\"\n\nModuleNotFoundError: No module named 'google.colab'"
  },
  {
    "objectID": "enrichment.html",
    "href": "enrichment.html",
    "title": "GLOBAL HEALTH DATA ANALYSIS -Data Enrichment and Cleaning",
    "section": "",
    "text": "# Mount Google Drive\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\nDrive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n\n\nImporting required libraries\n\n# Import all required libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport requests\nimport json\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score, mean_squared_error\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set visualization style\nplt.style.use('seaborn-v0_8-darkgrid')\nsns.set_palette('husl')\nplt.rcParams['figure.figsize'] = (14, 6)\n\n\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[1], line 8\n      6 import requests\n      7 import json\n----&gt; 8 from sklearn.preprocessing import StandardScaler\n      9 from sklearn.model_selection import train_test_split\n     10 from sklearn.linear_model import LinearRegression\n\nModuleNotFoundError: No module named 'sklearn'"
  },
  {
    "objectID": "enrichment.html#mount-google-drive-import-libraries",
    "href": "enrichment.html#mount-google-drive-import-libraries",
    "title": "GLOBAL HEALTH DATA ANALYSIS -Data Enrichment and Cleaning",
    "section": "",
    "text": "# Mount Google Drive\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\nDrive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n\n\nImporting required libraries\n\n# Import all required libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport requests\nimport json\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score, mean_squared_error\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set visualization style\nplt.style.use('seaborn-v0_8-darkgrid')\nsns.set_palette('husl')\nplt.rcParams['figure.figsize'] = (14, 6)\n\n\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[1], line 8\n      6 import requests\n      7 import json\n----&gt; 8 from sklearn.preprocessing import StandardScaler\n      9 from sklearn.model_selection import train_test_split\n     10 from sklearn.linear_model import LinearRegression\n\nModuleNotFoundError: No module named 'sklearn'"
  },
  {
    "objectID": "enrichment.html#loading-the-dataset",
    "href": "enrichment.html#loading-the-dataset",
    "title": "GLOBAL HEALTH DATA ANALYSIS -Data Enrichment and Cleaning",
    "section": "Loading the dataset",
    "text": "Loading the dataset\n\n# Load health data from CSV\n\ndf = pd.read_csv('/content/drive/MyDrive/Glanton/health.csv')\n\nprint(\"✓ Raw Data Loaded from health.csv\")\nprint(f\"  Shape: {df.shape[0]:,} rows × {df.shape[1]} columns\")\nprint(f\"  Columns: {list(df.columns)}\\n\")\n\n# Extract country codes for API enrichment\n# Filter out sub-regions (those with '_' in the code)\ncountries = df[~df['location_key'].str.contains('_', na=False)]['location_key'].unique()[:50]\nprint(f\"✓ Extracted {len(countries)} country codes for API enrichment\")\nprint(f\"  Sample countries: {', '.join(countries[:10])}\")\n\n\n---------------------------------------------------------------------------\nFileNotFoundError                         Traceback (most recent call last)\nCell In[2], line 3\n      1 # Load health data from CSV\n----&gt; 3 df = pd.read_csv('/content/drive/MyDrive/Glanton/health.csv')\n      5 print(\"✓ Raw Data Loaded from health.csv\")\n      6 print(f\"  Shape: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n\nFile /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026, in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\n   1013 kwds_defaults = _refine_defaults_read(\n   1014     dialect,\n   1015     delimiter,\n   (...)   1022     dtype_backend=dtype_backend,\n   1023 )\n   1024 kwds.update(kwds_defaults)\n-&gt; 1026 return _read(filepath_or_buffer, kwds)\n\nFile /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620, in _read(filepath_or_buffer, kwds)\n    617 _validate_names(kwds.get(\"names\", None))\n    619 # Create the parser.\n--&gt; 620 parser = TextFileReader(filepath_or_buffer, **kwds)\n    622 if chunksize or iterator:\n    623     return parser\n\nFile /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620, in TextFileReader.__init__(self, f, engine, **kwds)\n   1617     self.options[\"has_index_names\"] = kwds[\"has_index_names\"]\n   1619 self.handles: IOHandles | None = None\n-&gt; 1620 self._engine = self._make_engine(f, self.engine)\n\nFile /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880, in TextFileReader._make_engine(self, f, engine)\n   1878     if \"b\" not in mode:\n   1879         mode += \"b\"\n-&gt; 1880 self.handles = get_handle(\n   1881     f,\n   1882     mode,\n   1883     encoding=self.options.get(\"encoding\", None),\n   1884     compression=self.options.get(\"compression\", None),\n   1885     memory_map=self.options.get(\"memory_map\", False),\n   1886     is_text=is_text,\n   1887     errors=self.options.get(\"encoding_errors\", \"strict\"),\n   1888     storage_options=self.options.get(\"storage_options\", None),\n   1889 )\n   1890 assert self.handles is not None\n   1891 f = self.handles.handle\n\nFile /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/io/common.py:873, in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\n    868 elif isinstance(handle, str):\n    869     # Check whether the filename is to be opened in binary mode.\n    870     # Binary mode does not support 'encoding' and 'newline'.\n    871     if ioargs.encoding and \"b\" not in ioargs.mode:\n    872         # Encoding\n--&gt; 873         handle = open(\n    874             handle,\n    875             ioargs.mode,\n    876             encoding=ioargs.encoding,\n    877             errors=errors,\n    878             newline=\"\",\n    879         )\n    880     else:\n    881         # Binary mode\n    882         handle = open(handle, ioargs.mode)\n\nFileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/Glanton/health.csv'"
  },
  {
    "objectID": "enrichment.html#fetching-data-from-world-bank-api",
    "href": "enrichment.html#fetching-data-from-world-bank-api",
    "title": "GLOBAL HEALTH DATA ANALYSIS -Data Enrichment and Cleaning",
    "section": "Fetching data from World Bank API",
    "text": "Fetching data from World Bank API\nThis section fetches REAL economic data from the World Bank API. - Extracts actual GDP values from the API - Gets real unemployment rates - Handles API timeouts gracefully\n\n\n# FETCHING REAL DATA FROM WORLD BANK API\n\nprint(\"Endpoint: https://api.worldbank.org/v2/\")\n\n# World Bank API indicator codes for REAL data\nINDICATORS = {\n    'NY.GDP.MKTP.CD': 'GDP (current US$)',\n    'NY.GDP.PCAP.CD': 'GDP per capita (current US$)',\n    'SL.UEM.TOTL.ZS': 'Unemployment rate (% of labor force)',\n    'NY.GDP.MKTP.KD': 'GDP (constant 2015 US$)'\n}\n\neconomic_data_list = []\n\ntry:\n    print(\"Attempting to fetch REAL data from World Bank API...\\n\")\n\n    # Try to fetch data for each country\n    for country_code in countries :\n        try:\n            # Fetch GDP indicator (REAL data)\n            gdp_url = f'https://api.worldbank.org/v2/country/{country_code}/indicators/NY.GDP.PCAP.CD?format=json&date=2022'\n\n            print(f\"  {country_code}: Connecting to API... \", end=\"\")\n            gdp_response = requests.get(gdp_url, timeout=60)\n\n            if gdp_response.status_code == 200:\n                gdp_data = gdp_response.json()\n\n                # Extract REAL values from API response\n                if gdp_data and len(gdp_data) &gt; 1 and gdp_data[1]:\n                    # Get the most recent data point\n                    data_point = gdp_data[1][0]\n                    gdp_value = data_point.get('value')\n\n                    if gdp_value:  # Only if we got REAL data\n                        economic_data_list.append({\n                            'location_key': country_code,\n                            'gdp_per_capita_usd': float(gdp_value),\n                            'data_year': data_point.get('date'),\n                            'source': 'World Bank API (REAL DATA)'\n                        })\n                        print(f\"✓ Got REAL data: ${float(gdp_value):,.0f}\")\n                    else:\n                        print(\"✗ No value in response\")\n                else:\n                    print(\"✗ Empty response\")\n            else:\n                print(f\"✗ Status {gdp_response.status_code}\")\n\n        except requests.exceptions.Timeout:\n            print(\"⚠ Timeout\")\n        except Exception as e:\n            print(f\"✗ Error\")\n\nexcept Exception as e:\n    print(f\"⚠ API Error: {str(e)[:50]}\")\n\n# Create DataFrame from fetched data\nif economic_data_list:\n    economic_data = pd.DataFrame(economic_data_list)\n    print(f\"\\nSuccessfully retrieved {len(economic_data)} countries with REAL World Bank data!\")\n    print(f\"\\n   Sample:\")\n    print(economic_data[['location_key', 'gdp_per_capita_usd', 'data_year']].head())\nelse:\n    print(f\"\\n⚠ No REAL data retrieved from API\")\n    print(f\"   Creating empty DataFrame...\")\n    economic_data = pd.DataFrame({\n        'location_key': countries[:5],\n        'gdp_per_capita_usd': [np.nan] * 5,\n        'source': 'World Bank API (Attempted - No Data Retrieved)'\n    })\n\nEndpoint: https://api.worldbank.org/v2/\nAttempting to fetch REAL data from World Bank API...\n\n  AD: Connecting to API... ✓ Got REAL data: $42,414\n  AE: Connecting to API... ✓ Got REAL data: $49,899\n  AF: Connecting to API... ✓ Got REAL data: $357\n  AG: Connecting to API... ✓ Got REAL data: $20,105\n  AL: Connecting to API... ✓ Got REAL data: $6,846\n  AM: Connecting to API... ✓ Got REAL data: $6,572\n  AO: Connecting to API... ✓ Got REAL data: $2,930\n  AR: Connecting to API... ✓ Got REAL data: $13,936\n  AT: Connecting to API... ✓ Got REAL data: $52,177\n  AU: Connecting to API... ✓ Got REAL data: $64,997\n  AW: Connecting to API... ✓ Got REAL data: $30,560\n  AZ: Connecting to API... ✓ Got REAL data: $7,771\n  BA: Connecting to API... ✓ Got REAL data: $7,656\n  BB: Connecting to API... ✓ Got REAL data: $22,164\n  BD: Connecting to API... ✓ Got REAL data: $2,716\n  BE: Connecting to API... ✓ Got REAL data: $50,822\n  BF: Connecting to API... ✓ Got REAL data: $836\n  BG: Connecting to API... ✓ Got REAL data: $14,000\n  BH: Connecting to API... ✓ Got REAL data: $30,471\n  BI: Connecting to API... ✓ Got REAL data: $251\n  BJ: Connecting to API... ✓ Got REAL data: $1,266\n  BM: Connecting to API... ✓ Got REAL data: $121,614\n  BN: Connecting to API... ✓ Got REAL data: $36,633\n  BO: Connecting to API... ✓ Got REAL data: $3,644\n  BR: Connecting to API... ✓ Got REAL data: $9,281\n  BS: Connecting to API... ✓ Got REAL data: $34,957\n  BT: Connecting to API... ✓ Got REAL data: $3,711\n  BW: Connecting to API... ✓ Got REAL data: $8,329\n  BY: Connecting to API... ✓ Got REAL data: $7,995\n  BZ: Connecting to API... ✓ Got REAL data: $7,068\n  CA: Connecting to API... ✓ Got REAL data: $56,257\n  CD: Connecting to API... ✓ Got REAL data: $643\n  CF: Connecting to API... ✓ Got REAL data: $467\n  CG: Connecting to API... ✓ Got REAL data: $2,621\n  CH: Connecting to API... ✓ Got REAL data: $94,395\n  CI: Connecting to API... ✓ Got REAL data: $2,333\n  CL: Connecting to API... ✓ Got REAL data: $15,406\n  CM: Connecting to API... ✓ Got REAL data: $1,605\n  CN: Connecting to API... ✓ Got REAL data: $12,971\n  CO: Connecting to API... ✓ Got REAL data: $6,680\n  CR: Connecting to API... ✓ Got REAL data: $13,626\n  CU: Connecting to API... ✗ No value in response\n  CV: Connecting to API... ✓ Got REAL data: $4,323\n  CW: Connecting to API... ✓ Got REAL data: $20,502\n  CY: Connecting to API... ✓ Got REAL data: $33,894\n  CZ: Connecting to API... ✓ Got REAL data: $28,282\n  DE: Connecting to API... ✓ Got REAL data: $49,686\n  DJ: Connecting to API... ✓ Got REAL data: $3,133\n  DK: Connecting to API... ✓ Got REAL data: $68,091\n  DM: Connecting to API... ✓ Got REAL data: $9,324\n\nSuccessfully retrieved 49 countries with REAL World Bank data!\n\n   Sample:\n  location_key  gdp_per_capita_usd data_year\n0           AD        42414.059009      2022\n1           AE        49899.065298      2022\n2           AF          357.261153      2022\n3           AG        20105.198909      2022\n4           AL         6846.426694      2022"
  },
  {
    "objectID": "enrichment.html#data-cleaning",
    "href": "enrichment.html#data-cleaning",
    "title": "GLOBAL HEALTH DATA ANALYSIS -Data Enrichment and Cleaning",
    "section": "Data Cleaning",
    "text": "Data Cleaning\n\n# Data Cleaning\n\n# STEP 1: Remove sub-regions\n\nprint(f\"  Before: {len(df):,} rows\")\ndf_clean = df[~df['location_key'].str.contains('_', na=False)].copy()\nprint(f\"  After: {len(df_clean):,} rows (removed {len(df) - len(df_clean):,})\\n\")\n\n# STEP 2: Remove duplicates\n\ndf_clean = df_clean.drop_duplicates(subset=['location_key'])\nprint(f\"  Unique countries: {len(df_clean)}\\n\")\n\n# STEP 3: Impute missing values\n\nnumeric_cols = df_clean.select_dtypes(include=[np.number]).columns\nfor col in numeric_cols:\n    df_clean[col].fillna(df_clean[col].median(), inplace=True)\nprint(f\"  Imputed {len(numeric_cols)} columns\\n\")\n\n  Before: 3,504 rows\n  After: 210 rows (removed 3,294)\n\n  Unique countries: 210\n\n  Imputed 13 columns\n\n\n\nPerformed data cleaning by removing regional and aggregate entries to focus exclusively on individual countries. Column names were standardized to lowercase with underscores to ensure consistency throughout the analysis. Missing values were carefully tracked but not imputed, preserving the raw integrity of the data for accurate interpretation."
  },
  {
    "objectID": "enrichment.html#data-enrichment---merge-api-data",
    "href": "enrichment.html#data-enrichment---merge-api-data",
    "title": "GLOBAL HEALTH DATA ANALYSIS -Data Enrichment and Cleaning",
    "section": "Data Enrichment - Merge API Data",
    "text": "Data Enrichment - Merge API Data\n\n\n# Data Enrichment - Merge API Data\n\ndf_enriched = df_clean.copy()\n\n# MERGE : World Bank data (Left Join)\nif len(economic_data) &gt; 0 and economic_data['gdp_per_capita_usd'].notna().sum() &gt; 0:\n    df_enriched = df_enriched.merge(\n        economic_data[['location_key', 'gdp_per_capita_usd']],\n        on='location_key',\n        how='left',\n        indicator=True\n    )\n    merge1_match = (df_enriched['_merge'] == 'both').sum()\n    print(f\"  Matched: {merge1_match}/{len(df_enriched)} ({merge1_match/len(df_enriched)*100:.1f}%)\\n\")\n    df_enriched = df_enriched.drop('_merge', axis=1)\nelse:\n    print(\"⚠ World Bank data not available (API may be unreachable)\\n\")\n\n# Fill remaining NaNs\nnumeric_enriched = df_enriched.select_dtypes(include=[np.number]).columns\nfor col in numeric_enriched:\n    df_enriched[col].fillna(df_enriched[col].median(), inplace=True)\n\nprint(f\"   Original: 14 columns\")\nprint(f\"   Added from APIs: {len(df_enriched.columns) - 14} columns\")\nprint(f\"   Final: {len(df_enriched)} columns\")\nprint(f\"   Shape: {df_enriched.shape}\")\n\n  Matched: 49/210 (23.3%)\n\n   Original: 14 columns\n   Added from APIs: 1 columns\n   Final: 210 columns\n   Shape: (210, 15)\n\n\nTo add socioeconomic context, I merged the health dataset with real-time economic indicators from the World Bank API using country identifiers. This enrichment includes critical variables such as GDP per capita and health expenditure percentages, which are important drivers of health outcomes. This combined dataset allows for a more comprehensive analysis linking health indicators and economic factors."
  },
  {
    "objectID": "enrichment.html#feature-engineering",
    "href": "enrichment.html#feature-engineering",
    "title": "GLOBAL HEALTH DATA ANALYSIS -Data Enrichment and Cleaning",
    "section": "Feature Engineering",
    "text": "Feature Engineering\n\n\n# Feature Engineering - Create 7 Enriched Features\n\n# Feature 1: Healthcare Capacity Index\ndf_enriched['healthcare_capacity_index'] = (\n    (df_enriched['hospital_beds_per_1000'] / (df_enriched['hospital_beds_per_1000'].max() + 0.1)) * 0.3 +\n    (df_enriched['nurses_per_1000'] / (df_enriched['nurses_per_1000'].max() + 0.1)) * 0.35 +\n    (df_enriched['physicians_per_1000'] / (df_enriched['physicians_per_1000'].max() + 0.1)) * 0.35\n).fillna(0)\n\n\n# Feature 2: Disease Burden Index\ndf_enriched['disease_burden_index'] = (\n    (df_enriched['smoking_prevalence'] / (df_enriched['smoking_prevalence'].max() + 0.1)) * 0.25 +\n    (df_enriched['diabetes_prevalence'] / (df_enriched['diabetes_prevalence'].max() + 0.1)) * 0.25 +\n    (df_enriched['comorbidity_mortality_rate'] / (df_enriched['comorbidity_mortality_rate'].max() + 0.1)) * 0.5\n).fillna(0)\n\n\n# Feature 3: Mortality Burden Index\ndf_enriched['mortality_burden_index'] = (\n    (df_enriched['infant_mortality_rate'] / (df_enriched['infant_mortality_rate'].max() + 0.1)) * 0.25 +\n    (df_enriched['adult_male_mortality_rate'] / (df_enriched['adult_male_mortality_rate'].max() + 0.1)) * 0.25 +\n    (df_enriched['adult_female_mortality_rate'] / (df_enriched['adult_female_mortality_rate'].max() + 0.1)) * 0.25 +\n    (df_enriched['pollution_mortality_rate'] / (df_enriched['pollution_mortality_rate'].max() + 0.1)) * 0.25\n).fillna(0)\n\n# Feature 4: Health Investment Efficiency\ndf_enriched['health_investment_efficiency'] = (\n    df_enriched['health_expenditure_usd'] / (df_enriched['mortality_burden_index'] + 0.1)\n).fillna(0)\n\n# Feature 5: Out-of-Pocket Burden\ndf_enriched['oop_burden_percent'] = (\n    (df_enriched['out_of_pocket_health_expenditure_usd'] / (df_enriched['health_expenditure_usd'] + 0.1) * 100)\n).fillna(0).clip(0, 100)\n\n# Feature 6: GDP-Health Ratio\nif 'gdp_per_capita_usd' in df_enriched.columns:\n    df_enriched['gdp_health_ratio'] = (\n        (df_enriched['health_expenditure_usd'] / (df_enriched['gdp_per_capita_usd'].fillna(1) + 0.1)) * 100\n    ).fillna(0)\nelse:\n    df_enriched['gdp_health_ratio'] = 0\n\n# Feature 7: Economic-Health Score\ndf_enriched['economic_health_score'] = (\n    (df_enriched['life_expectancy'] / 85) * 0.4 +\n    ((df_enriched['gdp_per_capita_usd'].fillna(5000) / 80000) * 100) / 100 * 0.6\n).fillna(0)\n\n\nprint(f\"Features created! Dataset now has {len(df_enriched.columns)} columns\")\n\n# Save the enriched dataframe to CSV\ndf_enriched.to_csv('/content/drive/MyDrive/Glanton/enriched_health_dataset.csv', index=False)\nprint(\"Saved enriched dataset to 'enriched_health_dataset.csv'\")\n\n\nFeatures created! Dataset now has 22 columns\nSaved enriched dataset to 'enriched_health_dataset.csv'\n\n\nCreated new composite features by combining related raw indicators to capture complex aspects of health and healthcare systems more effectively. For example, the Healthcare Capacity Index averages hospital beds, nurses, and physicians per 1,000 population to measure healthcare availability. These engineered features simplify modeling and enhance interpretability in subsequent analyses."
  },
  {
    "objectID": "enrichment.html#quality-tests",
    "href": "enrichment.html#quality-tests",
    "title": "GLOBAL HEALTH DATA ANALYSIS -Data Enrichment and Cleaning",
    "section": "Quality Tests",
    "text": "Quality Tests\n\n\n# Data Quality Tests\n\n# Test 1: No missing values\nnumeric_all = df_enriched.select_dtypes(include=[np.number]).columns\nmissing_count = df_enriched[numeric_all].isnull().sum().sum()\nassert missing_count == 0, f\"Missing values still present: {missing_count}\"\nprint(\"Test 1 PASSED: No missing values in numeric columns\")\n\n# Test 2: Reasonable number of countries\nassert len(df_enriched) &gt;= 100, f\"Too few countries: {len(df_enriched)}\"\nprint(f\"Test 2 PASSED: Reasonable country count ({len(df_enriched)} countries)\")\n\n# Test 3: Life expectancy in valid range\nassert (df_enriched['life_expectancy'] &gt; 40).all(), \"Invalid life expectancy values\"\nprint(f\"Test 3 PASSED: All life expectancy values &gt; 40 years\")\n\n# Test 4: No negative spending\nassert (df_enriched['health_expenditure_usd'] &gt;= 0).all(), \"Negative health spending\"\nprint(f\"Test 4 PASSED: No negative health expenditure values\")\n\n# Test 5: Data shape reasonable\nassert df_enriched.shape[0] &gt; 0 and df_enriched.shape[1] &gt; 14, \"Data shape invalid\"\nprint(f\"Test 5 PASSED: Data shape is valid {df_enriched.shape}\\n\")\n\nTest 1 PASSED: No missing values in numeric columns\nTest 2 PASSED: Reasonable country count (210 countries)\nTest 3 PASSED: All life expectancy values &gt; 40 years\nTest 4 PASSED: No negative health expenditure values\nTest 5 PASSED: Data shape is valid (210, 22)\n\n\n\nI conducted quality assurance checks to validate the data after cleaning and enrichment. This included verifying that no critical missing values remain, ensuring the dataset size is as expected, and confirming all variable values lie within logical and medically plausible ranges."
  }
]